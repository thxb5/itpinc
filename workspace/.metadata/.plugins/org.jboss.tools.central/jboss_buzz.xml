<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>A developer’s guide to secure coding with FORTIFY_SOURCE</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/07/04/developers-guide-secure-coding-fortifysource" /><author><name>Sandipan Roy</name></author><id>918ec339-c4e6-46d8-90a1-4892a2b0ff47</id><updated>2023-07-04T07:00:00Z</updated><published>2023-07-04T07:00:00Z</published><summary type="html">&lt;p&gt;Secure coding is essential to building robust and resilient software that is less susceptible to exploitation by attackers. One way to ensure secure coding is to use a feature called FORTIFY_SOURCE. In this article, we will explore FORTIFY_SOURCE and how it can be used to enhance the security of your code.&lt;/p&gt; &lt;h2&gt;What is FORTIFY_SOURCE?&lt;/h2&gt; &lt;p&gt;FORTIFY_SOURCE is a feature available in the GNU C Library that provides runtime protection against certain types of security vulnerabilities. Specifically, FORTIFY_SOURCE detects and prevents buffer overflow and formats string vulnerabilities, which are two common types of vulnerabilities that attackers can exploit to take control of a system or steal sensitive data.&lt;/p&gt; &lt;h2&gt;How does FORTIFY_SOURCE work?&lt;/h2&gt; &lt;p&gt;FORTIFY_SOURCE works by providing enhanced versions of certain C library functions that can detect when a buffer overflow or format string vulnerability is about to occur. When a vulnerable function is called, FORTIFY_SOURCE checks the size of the buffer being used and ensures that it is not being overrun. If an overflow or vulnerability is detected, FORTIFY_SOURCE immediately terminates the program to prevent further damage.&lt;/p&gt; &lt;p&gt;For example, consider the following code snippet:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;char buffer[8]; strcpy(buffer, "hello world");&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In this code, the &lt;code&gt;strcpy&lt;/code&gt; function is used to copy the "hello world" string into the &lt;code&gt;buffer&lt;/code&gt; variable. However, the &lt;code&gt;buffer&lt;/code&gt; variable is only allocated eight bytes of memory, which is not enough to hold the entire string. This results in a buffer overflow vulnerability that can be exploited by attackers.&lt;/p&gt; &lt;p&gt;If FORTIFY_SOURCE is enabled, the &lt;code&gt;strcpy&lt;/code&gt; function is replaced by a secure version that checks the size of the buffer and prevents an overflow from occurring. In this case, the program would terminate before the vulnerability could be exploited.&lt;/p&gt; &lt;p&gt;Consider another code snippet:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;char password[16]; scanf("%s", password);&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In this code, the &lt;code&gt;scanf&lt;/code&gt; function is used to read input from the user and store it in the &lt;code&gt;password&lt;/code&gt; variable. However, the &lt;code&gt;scanf&lt;/code&gt; function does not perform any bounds checking, which means that if the user enters more than 16 characters, a buffer overflow vulnerability could occur.&lt;/p&gt; &lt;p&gt;To mitigate this vulnerability using FORTIFY_SOURCE, you can use the secure version of &lt;code&gt;scanf&lt;/code&gt;, called &lt;code&gt;scanf_s&lt;/code&gt;, which checks the size of the buffer and prevents an overflow from occurring. Here's how the code would look using &lt;code&gt;scanf_s&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;char password[16]; scanf_s("%15s", password, sizeof(password));&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In this code, &lt;code&gt;scanf_s&lt;/code&gt; takes an additional parameter that specifies the maximum number of characters that can be read from the user. In this case, we set the maximum length to 15, which leaves one byte for the null terminator that is added to the end of the string.&lt;/p&gt; &lt;p&gt;By using &lt;code&gt;scanf_s&lt;/code&gt; instead of &lt;code&gt;scanf&lt;/code&gt;, we can prevent buffer overflow vulnerabilities in our code.&lt;/p&gt; &lt;h2&gt;How to use FORTIFY_SOURCE&lt;/h2&gt; &lt;p&gt;To use FORTIFY_SOURCE in your code, you must first ensure that it is enabled in your development environment. FORTIFY_SOURCE is &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;typically enabled or disabled by invoking &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;D_FORTIFY_SOURCE &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;compiler flags. I&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;t is enabled by default in rpm macros and used when building all packages, but other uses of GCC need to explicitly enable it.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Follow these steps:&lt;/p&gt; &lt;ol&gt;&lt;li&gt; &lt;p&gt;Compile your code using a compiler that supports FORTIFY_SOURCE. Most modern C compilers, such as GCC and Clang, support this feature.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Enable FORTIFY_SOURCE using the appropriate compiler flag. The flag may vary depending on your compiler and version, but for GCC, you can use the &lt;code&gt;-D_FORTIFY_SOURCE=2&lt;/code&gt; flag to enable the feature.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Compile your code with the appropriate optimization level. FORTIFY_SOURCE is most effective when the code is compiled with optimization enabled, so be sure to use at least &lt;code&gt;-O1&lt;/code&gt; optimization level.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Here's an example command to compile your code with FORTIFY_SOURCE enabled using GCC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;gcc -D_FORTIFY_SOURCE=2 -O1 -o myprogram myprogram.c&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once your code is compiled with FORTIFY_SOURCE enabled, the enhanced secure library functions provided by the feature will automatically replace the standard C library functions, such as &lt;code&gt;strcpy&lt;/code&gt;, &lt;code&gt;scanf&lt;/code&gt;, and &lt;code&gt;printf&lt;/code&gt;. This means that any calls to these functions in your code will be automatically replaced with the secure versions provided by FORTIFY_SOURCE.&lt;/p&gt; &lt;p&gt;Once FORTIFY_SOURCE is enabled, you can use the enhanced secure library functions provided by the feature instead of the standard C library functions. For example, you can use &lt;code&gt;strncpy_s&lt;/code&gt; instead of &lt;code&gt;strcpy&lt;/code&gt; to safely copy a string into a buffer.&lt;/p&gt; &lt;p&gt;It is important to note that FORTIFY_SOURCE does not provide complete protection against all types of security vulnerabilities. It only protects against buffer overflow and format string vulnerabilities. Therefore, it is important to use other secure coding practices in conjunction with FORTIFY_SOURCE to ensure that your code is as secure as possible.&lt;/p&gt; &lt;h2&gt;Advanced usage of FORTIFY_SOURCE&lt;/h2&gt; &lt;p&gt;When using FORTIFY_SOURCE, you can specify a level of protection between 0 and 3. The higher the level, the more security features are enabled. The default level is 1.&lt;/p&gt; &lt;p&gt;FORTIFY_SOURCE=3 provides the highest level of protection and includes all the security features of levels 1 and 2, plus additional checks for potentially dangerous constructs in the code. These additional checks are designed to detect a wider range of security issues, including:&lt;/p&gt; &lt;ul&gt;&lt;li&gt; &lt;p&gt;Dangerous use of memcpy and memmove functions.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Dangerous use of snprintf, vsnprintf, and similar functions.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Dangerous use of string manipulation functions like strtok, strncat, and strpbrk.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt;&lt;p&gt;However, it's important to note that enabling FORTIFY_SOURCE=3 may have some performance implications, as it adds additional code to perform the security checks. &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Therefore, it might be desirable to use a lower level of protection in performance critical code but the programmer must be mindful of additional security risks.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;To enable FORTIFY_SOURCE=3, you can use the &lt;code&gt;-O2&lt;/code&gt; optimization level in addition to the &lt;code&gt;-D_FORTIFY_SOURCE=3&lt;/code&gt; flag when compiling your code with GCC. Here's an example command to enable FORTIFY_SOURCE=3:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;gcc -D_FORTIFY_SOURCE=3 -O2 -o myprogram myprogram.c&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;FORTIFY_SOURCE=3 provides the highest level of protection against security issues in C and C++ programs, but it may come at a performance cost. Therefore, it's important to carefully consider the level of protection you need and balance it with the performance requirements of your application.&lt;/p&gt; &lt;h3&gt;How to check FORTIFY_SOURCE&lt;/h3&gt; &lt;p&gt;In this example, we're copying a string that is longer than the size of the &lt;code&gt;buf&lt;/code&gt; array, which can lead to a buffer overflow if FORTIFY_SOURCE is not enabled.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;#include &lt;stdio.h&gt; #include &lt;string.h&gt; int main() { char buf[10]; strcpy(buf, "1234567890"); printf("%s\n", buf); return 0; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To enable FORTIFY_SOURCE, we can compile the code with the &lt;code&gt;-O2&lt;/code&gt; optimization flag and the &lt;code&gt;-D_FORTIFY_SOURCE=2&lt;/code&gt; preprocessor flag:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;gcc -O2 -D_FORTIFY_SOURCE=2 -o test test.c&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now when we run the program, we should see a runtime error indicating that a buffer overflow has occurred.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;*** buffer overflow detected ***: ./test terminated Aborted (core dumped)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Also, we can use &lt;code&gt;objdump&lt;/code&gt; to examine the compiled binary and look for references to FORTIFY_SOURCE. We can use the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;objdump -R test&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This will show us the dynamic relocations table for our binary, which includes information about any shared libraries or symbols used by the program.&lt;/p&gt; &lt;p&gt;If FORTIFY_SOURCE is enabled, we should see a reference to the symbol &lt;code&gt;__strcpy_chk&lt;/code&gt; in the relocations table, which is a fortified version of the &lt;code&gt;strcpy&lt;/code&gt; function that performs runtime checks for buffer overflows.&lt;/p&gt; &lt;p&gt;Here's an example of what the output might look like if FORTIFY_SOURCE is enabled:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;test: file format elf64-x86-64 DYNAMIC RELOCATION RECORDS ... 0000000000601018 R_X86_64_JUMP_SLOT __strcpy_chk@GLIBC_2.3.4 ...&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This indicates that our program is using the fortified &lt;code&gt;__strcpy_chk&lt;/code&gt; function, which is provided by the GNU C library and performs runtime checks to prevent buffer overflows.&lt;/p&gt; &lt;p&gt;Examining the dynamic relocation table of our compiled binary with &lt;code&gt;objdump&lt;/code&gt;, we can check if FORTIFY_SOURCE is enabled and ensure that our code is properly secured against common security issues.&lt;/p&gt; &lt;p&gt;We can also use &lt;code&gt;checksec&lt;/code&gt; tool which primarily used for assessing the security features and hardening options of an executable or shared object file. While it is not specifically designed to check for the presence of FORTIFY_SOURCE in a binary, it can provide valuable information about the overall security posture of the program.&lt;/p&gt; &lt;p&gt;When using &lt;code&gt;checksec&lt;/code&gt; to assess a binary that has been compiled with FORTIFY_SOURCE, it can indicate the presence of certain security features that are commonly enabled by FORTIFY_SOURCE, such as stack canaries or enhanced buffer overflow protections. &lt;code&gt;checksec&lt;/code&gt; can also detect other security mitigations that may have been enabled during compilation, such as Address Space Layout Randomization (ASLR) or Data Execution Prevention (DEP).&lt;/p&gt; &lt;p&gt;Lets see the output of running checksec against our test program:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;$ checksec --file=./test RELRO STACK CANARY NX PIE RPATH RUNPATH FILE Full RELRO Canary found NX enabled PIE enabled No RPATH No RUNPATH test &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In the output, we can observe the following several security features being reported.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Full RELRO&lt;/strong&gt; indicates that all relocations have been resolved at load time, providing protection against certain types of attacks like GOT (Global Offset Table) overwrite attacks.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Canary found&lt;/strong&gt;: The presence of a stack canary indicates the usage of a security mechanism designed to detect stack-based buffer overflows. FORTIFY_SOURCE often enables stack canaries to protect against these types of vulnerabilities.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;NX enabled&lt;/strong&gt;: NX (Non-Executable) marking prevents the execution of code in memory regions that are intended for data. This feature enhances security by preventing the execution of injected or malicious code.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;PIE enabled&lt;/strong&gt;: Position Independent Executable (PIE) makes the binary's base address random, providing Address Space Layout Randomization (ASLR) to thwart memory-based attacks. Fortify Source can be used in combination with PIE to strengthen the overall security of the executable.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;While this output doesn't explicitly state the usage of FORTIFY_SOURCE, the presence of stack canaries and other security features suggests that the binary may have been compiled with FORTIFY_SOURCE or similar security-enhancing techniques. To confirm the usage of FORTIFY_SOURCE, it's best to refer to the build configuration or examine the compiler flags and options used during the compilation process.&lt;/p&gt; &lt;h2&gt;FORTIFY_SOURCE improves code security&lt;/h2&gt; &lt;p&gt;FORTIFY_SOURCE is a valuable feature that can enhance the security of your code by providing runtime protection against buffer overflow and format string vulnerabilities. By enabling FORTIFY_SOURCE in your development environment and using secure library functions, you can reduce the risk of security vulnerabilities in your code. Remember that FORTIFY_SOURCE is just one tool in your toolbox and should be used in conjunction with other secure coding practices to ensure the security of your code.&lt;/p&gt; &lt;p&gt;For more information, refer to these articles:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://www.redhat.com/en/blog/security-technologies-fortifysource" target="_blank"&gt;Security Technologies: FORTIFY_SOURCE&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.redhat.com/en/blog/enhance-application-security-fortifysource" target="_blank"&gt;Enhance application security with FORTIFY_SOURCE&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2021/04/16/broadening-compiler-checks-for-buffer-overflows-in-_fortify_source" target="_blank"&gt;Broadening compiler checks for buffer overflows in FORTIFYSOURCE&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.redhat.com/en/blog/hardening-elf-binaries-using-relocation-read-only-relro"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hardening ELF binaries using Relocation Read-Only (RELRO)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/07/04/developers-guide-secure-coding-fortifysource" title="A developer’s guide to secure coding with FORTIFY_SOURCE"&gt;A developer’s guide to secure coding with FORTIFY_SOURCE&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Sandipan Roy</dc:creator><dc:date>2023-07-04T07:00:00Z</dc:date></entry><entry><title type="html">Camel Routes support in Serverless Workflow Editors</title><link rel="alternate" href="https://blog.kie.org/2023/07/camel-routes-support-in-serverless-workflow-editors.html" /><author><name>Saravana Balaji</name></author><id>https://blog.kie.org/2023/07/camel-routes-support-in-serverless-workflow-editors.html</id><updated>2023-07-03T12:49:44Z</updated><content type="html">The Serverless Workflow Editor now offers autocomplete features for functions and events via Catalog Explorer. In my previous blog posts, we saw how and support OpenAPI and AsyncAPI specifications.The same feature now works with Camel Routes as well. While editing Serverless Workflow files, you can register Camel Routes and pass them as functions. These functions will be available on the Serverless Workflow Editor’s Service Catalog Explorer. This article explains how that works. A Camel Route is a set of processing steps that are applied to a message as it travels from a source to a destination.  A Route typically consists of a series of processing steps that are connected in a linear sequence. At this point, Camel Routes are supported by KIE Serverless Workflow VS Code extension and soon the feature will be available on Web Tools as well. INSTALLING THE EXTENSION To proceed further, you will need and the . There are several ways to download and install the KIE Serverless Workflow VS Code extension 1. Download it from the . 2. Launch VS Code Quick Open (Ctrl+P), paste the following commands, and press enter: * ext install kie-group.swf-vscode-extension; 3. Click on the Extensions icon in the Activity Bar on the side of VS Code, search and install. * CAMEL ROUTE SAMPLE After installing the KIE Serverless Workflow VS Code Extension, open your Serverless Workflow project on your workspace and create a folder named “routes” inside the “main/properties” folder. If you have a Camel Routes file, you can place it there. This folder must only contain files that have Camel Routes content. This will be automatically read by the extension and populated on the editor. You can also copy the below sample content and paste it on a file that you can create inside the routes folder. - from: uri: direct:numberToWords steps: - bean: beanType: java.math.BigInteger method: valueOf - setHeader: name: operationName constant: NumberToWords - toD: uri: cxf://example.com?serviceClass=com.dataaccess.webservicesserver.NumberConversionSoapType&amp;amp;wsdlURL=/wsdl/numberconversion.wsdl CAMEL ROUTES AUTOCOMPLETE Once you have the file containing Camel Routes in place, the editor is intelligent enough to automatically read through the files and parse the Camel Routes. Here is a short demo showing how it works. Notice the new custom function with a new operation type. The operation is a URI scheme composed by the constant “camel:”, the “direct:” endpoint, and its name. The Serverless Workflow Editor only supports producing messages to a endpoint at this time. This function can be referenced in other definitions like state or events. To explore and understand the Serverless Workflow Editor with the help of samples, you can try out sample projects from. That’s all for now! There are more exciting features coming up in this space, stay tuned! The post appeared first on .</content><dc:creator>Saravana Balaji</dc:creator></entry><entry><title type="html">Migrating from Java 8 to Java 17 with OpenRewrite</title><link rel="alternate" href="https://www.mastertheboss.com/java/migrating-from-java-8-to-java-17-with-openrewrite/" /><author><name>F.Marchioni</name></author><id>https://www.mastertheboss.com/java/migrating-from-java-8-to-java-17-with-openrewrite/</id><updated>2023-07-03T12:07:29Z</updated><content type="html">In this article we will discuss on how to migrate Java applications from Java 8 to Java 17 using the OpenRewrite migration plugin. At the end of this tutorial, you will learn which are most common challenges that you can face when upgrading to Java 17 Java 8 to Java 17 challenges In pure project ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Managing Java containers with Quarkus and Podman Desktop</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/07/03/managing-java-containers-quarkus-and-podman-desktop" /><author><name>Kevin Dubois</name></author><id>8583d285-7edc-424d-b23b-c34c531c6661</id><updated>2023-07-03T07:00:00Z</updated><published>2023-07-03T07:00:00Z</published><summary type="html">&lt;p&gt;The world of software development is changing quickly, and it is no different for the &lt;a href="https://developers.redhat.com/java"&gt;Java&lt;/a&gt; developer who needs to learn new skills to manage Java containers.&lt;/p&gt; &lt;p&gt;In the traditional Java development world, it was rather typical to build a Java artifact (whether it be a .jar, .war, or .ear), and "throw it over the wall" for the middleware and operations people to take care of. It kind of made sense, too, because configuring and running enterprise application servers was not always that easy, and in the end, the developer's laptop would probably not match the specs of staging or production environments so that the configuration would be different anyway. We all know the "It works on my machine" cliché, after all.&lt;/p&gt; &lt;p&gt;These days, things need faster and better delivery, and production issues often require resolution in a very timely manner because every second of downtime could potentially cause revenue loss for an organization. New ways of delivering applications have been conceived—and with it, cloud-native applications, &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/topics/devops"&gt;DevOps&lt;/a&gt;—and the "but it worked on my machine" excuse is no longer valid.&lt;/p&gt; &lt;p&gt;Java developers need to be able to work with containers because it is a practical way to test applications in a production-like environment on their local machine. Some developers and organizations choose to take development off the local machine and right into the cloud with the IDE itself running in a reproducible, containerized environment for even greater consistency. &lt;a href="https://developers.redhat.com/products/openshift-dev-spaces/overview"&gt;Red Hat OpenShift Dev Spaces&lt;/a&gt; is one way you can do this, but it is out of the scope of this article.&lt;/p&gt; &lt;h2&gt;Building containers with Java&lt;/h2&gt; &lt;p&gt;Building and managing containers can become overwhelming rather quickly for the Java developer, though. At the face of it, it's "just" a matter of creating a Dockerfile with instructions to copy the artifact into a base image and doing a Docker build. However, in reality, creating a container image from an application requires many more considerations than that.&lt;/p&gt; &lt;h3&gt;Choosing a base image&lt;/h3&gt; &lt;p&gt;To start with, you will need a base image: do you start from scratch, adding every dependency individually, or use a base image that already has a Java Virtual Machine (JVM) implementation included? Or maybe you've opted to do a &lt;a href="https://quarkus.io/guides/building-native-image"&gt;native build&lt;/a&gt; of the application and don't need a JVM running in your container. Either way, you will need to find a trusted source that provides tested, secured, ideally signed, &lt;a href="https://opencontainers.org/about/overview/"&gt;Open Container Initiative (OCI)&lt;/a&gt;-compliant, and stable images for the particular Java version you are targeting. And hopefully, this source can provide support and maintain and backport patches going forward. The base image will likely need tuning as well to optimize performance, not something every developer is familiar with.&lt;/p&gt; &lt;p&gt;Red Hat's &lt;a href="https://www.redhat.com/en/blog/introducing-red-hat-universal-base-image"&gt;Universal Base Images (UBI)&lt;/a&gt; are a good starting point for building container images. UBIs are &lt;a href="https://developers.redhat.com/articles/ubi-faq#ubi_details"&gt;free to use&lt;/a&gt;, and they are at the core a subset of the Red Hat Linux (RHEL) distribution, providing a stable, secure, optimized and reliable base for building containers. There are several &lt;a href="https://catalog.redhat.com/software/containers/search?q=openjdkp=1"&gt; JVM-based UBI images&lt;/a&gt; available, as well as micro UBIs for deploying native binaries.&lt;/p&gt; &lt;h3&gt;Building the container image&lt;/h3&gt; &lt;p&gt;Once you have decided on a base image, you will need a way to build the container image. The best-known way is to create a Dockerfile (or Containerfile as the more agnostic way of naming such a file) and then build it with Docker.&lt;/p&gt; &lt;p&gt;This is certainly not the only way to build containers, though. You can use the same Containerfile to build an image with Podman, a fully open source container engine with actually &lt;a href="https://docs.podman.io/en/latest/"&gt;quite a few more features than the Docker engine&lt;/a&gt;. You could also use &lt;a href="https://buildah.io/"&gt;Buildah&lt;/a&gt;, another open source tool specifically created for building container images.&lt;/p&gt; &lt;p&gt;There are alternative ways of building containers without needing a Containerfile. There are build tools such as &lt;a href="https://github.com/openshift/source-to-image"&gt;Source2Image (S2I)&lt;/a&gt;, &lt;a href="https://buildpacks.io/"&gt;Buildpacks&lt;/a&gt;, &lt;a href="https://github.com/GoogleContainerTools/jib"&gt;Jib&lt;/a&gt;, and many more. These vary in complexity, but each one aims to streamline the container build process, particularly for developers.&lt;/p&gt; &lt;p&gt;Jib, for example, is a build tool specifically created for building container images with Java. S2I is a tool that take can take source code, do an introspection to see what kind of application it is (e.g., the presence of a &lt;code&gt;pom.xml&lt;/code&gt; would indicate that it is a Java application), and then build a container image from the application's source code using build images that are predefined by the S2I tool, or custom build images provided by the user. Buildpacks work similarly but require a buildpack builder image.&lt;/p&gt; &lt;p&gt;The downside is that you will need to install a specific command line interface (CLI) program for each of these container build tools and understand how to use them. Moreover, you will need to know what base images these build tools use (if applicable) or supply your own and figure out whether they are safe to use.&lt;/p&gt; &lt;p&gt;For further information on container terminology, Scott McCarty wrote a comprehensive introduction in &lt;a href="https://developers.redhat.com/blog/2018/02/22/container-terminology-practical-introduction#container_orchestration"&gt;this article&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;How Quarkus helps with Containerfiles&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/quarkus/getting-started"&gt;Quarkus &lt;/a&gt;is a Java stack that aims to make cloud-native development easier for the Java developer. Quarkus will supply Containerfiles from the moment the developer bootstraps a Quarkus application, whether it is through the &lt;a href="https://quarkus.io/guides/cli-tooling"&gt;Quarkus CLI&lt;/a&gt;'s command &lt;code&gt;quarkus create app&lt;/code&gt;, by generating a starter project on &lt;a href="https://code.quarkus.io/"&gt;code.quarkus.io&lt;/a&gt;, or by using one of the &lt;a href="https://quarkus.io/blog/vscode-quarkus-1.13.0-released/"&gt;Quarkus plug-ins&lt;/a&gt; in VS Code or IntelliJ.&lt;/p&gt; &lt;p&gt;By bootstrapping a new Quarkus application, a folder is created in &lt;code&gt;src/main/docker&lt;/code&gt; with prebaked Containerfiles (named &lt;code&gt;Dockerfile.*&lt;/code&gt; in this case) based on the UBI images previously mentioned in this article (Figure 1).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-04-28_18-36-35.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-04-28_18-36-35.png?itok=roN3aXaF" width="317" height="224" alt="Dockerfiles supplied by Quarkus upon bootstrapping an application" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: Dockerfiles supplied by Quarkus upon bootstrapping an application.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Quarkus supplies 4 different Containerfiles for different use cases:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;&lt;code&gt;Dockerfile.jvm&lt;/code&gt; is used by default to build a Java container that runs the Quarkus application in JVM mode.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;code&gt;Dockerfile.legacy-jar&lt;/code&gt; is used if for the legacy-jar packaging type (&lt;a href="https://quarkus.io/blog/quarkus-1-12-0-final-released/#fast-jar-as-default"&gt;more information on legacy vs fast-jar in Quarkus&lt;/a&gt;).&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;code&gt;Dockerfile.native&lt;/code&gt; uses a UBI without JVM for running natively compiled Quarkus apps.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;code&gt;Dockerfile.native-micro&lt;/code&gt; is a &lt;a href="https://quarkus.io/guides/quarkus-runtime-base-image"&gt;custom built micro UBI image&lt;/a&gt; to run native Quarkus apps.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;These Containerfiles can be used with regular Docker or Podman commands, but Quarkus also enables building container images directly from build tools such as Maven or Gradle. Basically, you can build an image with, for example, &lt;code&gt;mvn package quarkus:image-build&lt;/code&gt; and Quarkus will automatically build a container image using, by default, the &lt;code&gt;Dockerfile.jvm&lt;/code&gt; that came with the Quarkus project.&lt;/p&gt; &lt;p&gt;Similarly, to build an image without a JVM that runs a natively compiled binary, one must simply add the &lt;code&gt;--Dnative&lt;/code&gt; parameter to the command (in this case, Maven) , e.g., &lt;code&gt;mvn package quarkus:image-build -Dnative&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;There's one caveat with the latter command. You will need to install the &lt;a href="https://www.graalvm.org/latest/reference-manual/native-image/"&gt;GraalVM Native Image Builder&lt;/a&gt; executable (called native-image). Quarkus, however, has an alternative way to leverage GraalVM's Native Image Build without installing the native-image executable locally. Quarkus will, in fact, detect the absence of the native-image executable and attempt to download a container image that contains the bits to do a native Java compilation and actually build the native binary in a container (provided you have Docker or Podman installed, of course). The native binary builder image is based on &lt;a href="https://developers.redhat.com/blog/2021/04/14/mandrel-a-specialized-distribution-of-graalvm-for-quarkus"&gt;Mandrel&lt;/a&gt;, a downstream distribution of the GraalVM community edition whose main goal is to provide a native-image release specifically to support Quarkus.&lt;/p&gt; &lt;h2&gt;More CLI magic with Quarkus&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://quarkus.io/guides/cli-tooling"&gt;Quarkus CLI&lt;/a&gt; is, in essence, a convenience wrapper around the Maven or Gradle build tools that let you create projects, start Quarkus in dev and test mode, manage extensions and do essential build, dev, and even deploy. It provides a way to control the full inner-loop development experience without having to switch tools.&lt;/p&gt; &lt;p&gt;Thanks to the Quarkus CLI, you can execute simple commands that are easy to remember, such as &lt;code&gt;quarkus image build&lt;/code&gt;. Behind the scenes, Quarkus will invoke the chosen build tool, package the application, and build a container image using the previously mentioned Containerfiles and a local Docker or Podman instance (as shown in Figure 2).&lt;/p&gt; &lt;p&gt;Similarly, to use either Jib or Buildpacks, you can run the same command and append the container build tool of your preference, e.g., &lt;code&gt;quarkus image build jib&lt;/code&gt;, or &lt;code&gt;quarkus image build buildpack&lt;/code&gt;.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-05-15_13-54-00.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-05-15_13-54-00.png?itok=2Ml9XAXI" width="600" height="151" alt="Quarkus container image build success message" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: Image build success message after running quarkus image build.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The Quarkus CLI lets you push a container image to a registry as well with &lt;code&gt;quarkus image push&lt;/code&gt;. In fact, the application build, container build, and container push can be done in one go by adding the --also-build flag, e.g., &lt;code&gt;quarkus image push --also-build&lt;/code&gt;. Or, as a natively compiled binary, &lt;code&gt;quarkus image push --also-build --native&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Managing and running your container with Podman Desktop&lt;/h2&gt; &lt;p&gt;Once the container image has been built, you will likely want to run the container to make sure it actually works, or perhaps to use it with other applications. You could learn how to use Podman or Docker commands such as &lt;code&gt;podman run&lt;/code&gt; or &lt;code&gt;docker run;&lt;/code&gt; however, you will need to have at least some expertise in these tools to expose ports, mount volumes, execute commands, etc.&lt;/p&gt; &lt;p&gt;&lt;a href="https://podman-desktop.io"&gt;Podman Desktop&lt;/a&gt; is a UI tool that makes running and managing containers much easier with an intuitive user experience. You can install it on Windows (with WSL), macOS, and Linux, and it will install the underlying Podman utility as well, if needed.&lt;/p&gt; &lt;p&gt;You can spin up a container from the images view by clicking the play button next to the container image, as shown in Figure 2. You can then customize the container runtime configuration or let Podman automatically map the container's external port to the app's internal port based on the &lt;code&gt;EXPOSE&lt;/code&gt; value of the image (by default, &lt;code&gt;8080&lt;/code&gt; in Quarkus). Podman can automatically figure out if another process on the machine is already using that port and reassign the container's external port to use a different one instead. This is an impressive feature, in contrast to having to manually figure out if a port is being used on your machine with a command such as &lt;code&gt;netstat&lt;/code&gt; or &lt;code&gt;lsof&lt;/code&gt;, which is typically more in the realm of a system administrator.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/podman-desktop-start-container_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/podman-desktop-start-container_0.png?itok=RTAPDlKV" width="600" height="384" alt="Podman Desktop Images view with the cursor hovering over the start container button" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: Podman Desktop's Images view with "play" button to start a container.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;More Podman Desktop features&lt;/h2&gt; &lt;p&gt;Podman Desktop can do more than just run containers. For example, you might want to ssh into a container to do debugging or access or even modify settings. Using the CLI, you would have to find out the name of your container (e.g., with &lt;code&gt;podman ps&lt;/code&gt;) and then remember a command like &lt;code&gt;podman exec -it CONTAINER_ID /bin/bash&lt;/code&gt;. With Podman Desktop, it's as simple as selecting the container in the container view and clicking the &lt;strong&gt;Terminal&lt;/strong&gt; tab.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/podman-desktop-terminal.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/podman-desktop-terminal.png?itok=zQgSlTio" width="600" height="412" alt="Podman Desktop showing the container terminal view" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: Executing commands in a terminal inside a container with Podman Desktop.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Similarly, if you want to access the logs of a container, you can click the &lt;strong&gt;Logs&lt;/strong&gt; tab, or if you want to inspect the state of a container—e.g., to see what file systems it's using, what environment variables are set, etc.—then you could just click &lt;strong&gt;Inspect&lt;/strong&gt;.&lt;/p&gt; &lt;h3&gt;Using pods outside of Kubernetes&lt;/h3&gt; &lt;p&gt;Podman Desktop, as its name implies, can also run containers as pods. You could, for example, run another container, such as a caching database (Redis or Infinispan), and combine it with the application's container into a pod resulting in a single deployable and scalable unit that shares networking, just like one would run a pod on Kubernetes.&lt;/p&gt; &lt;h3&gt; Kubernetes and Podman Desktop&lt;/h3&gt; &lt;p&gt;It is possible to deploy containers or pods from Podman Desktop directly to a Kubernetes instance as well (Figure 3). To do so, simply click the rocket icon in the top right of the Podman Desktop view. Podman Desktop will detect a Kubernetes context (provided you are logged in to a Kubernetes cluster using, e.g., &lt;code&gt;kubectl login&lt;/code&gt;) and proceed to deploy the container(s) on a cluster as pods.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/podman-desktop-deploy-kubernetes.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/podman-desktop-deploy-kubernetes.png?itok=02W-YZn1" width="600" height="258" alt="Podman Desktop showing the deploy to kubernetes button" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: Podman Desktop's Logs view, with the Deploy to Kubernetes button highlighted.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;If a Kubernetes cluster is unavailable, Podman Desktop can start a Kubernetes-in-Docker (Kind) cluster through the Kind extension, available in the Podman Desktop settings.&lt;/p&gt; &lt;p&gt;Another alternative is to create a no-cost &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt; instance. You can provision one by visiting &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;developers.redhat.com/developer-sandbox&lt;/a&gt; and following the Create a free OpenShift Sandbox instance. This gives you a fully functional Kubernetes instance you can use to deploy your containerized application(s) to, and perhaps even expose the application to the world with!&lt;/p&gt; &lt;h2&gt;Get started today&lt;/h2&gt; &lt;p&gt;Building and running Java containers has become much easier over the years. Using frameworks such as Quarkus and tools like Podman Desktop and OpenShift make it simple to start working with containers, even for Java developers who have are new to the cloud-native world.&lt;/p&gt; &lt;p&gt;Try it today by &lt;a href="https://quarkus.io/get-started/"&gt;creating a Quarkus application&lt;/a&gt;, &lt;a href="https://quarkus.io/guides/container-image"&gt;building it into a container image&lt;/a&gt;, and &lt;a href="https://podman-desktop.io/docs/getting-started/starting-a-container"&gt;running it on Podman Desktop&lt;/a&gt;. &lt;/p&gt; &lt;h3&gt;Additional resources&lt;/h3&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2023/03/01/podman-desktop-introduction"&gt;What is Podman Desktop? A developer's introduction&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2023/05/23/podman-desktop-now-generally-available"&gt;Podman Desktop 1.0: Local container development made easy&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2023/06/09/deploy-and-test-kubernetes-containers-using-podman-desktop"&gt;Tutorial: Deploy and test Kubernetes containers using Podman Desktop&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/12/12/kubernetes-native-inner-loop-development-quarkus"&gt;Kubernetes-native inner loop development with Quarkus&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/05/31/learn-quarkus-faster-quick-starts-developer-sandbox-red-hat-openshift"&gt;Learn Quarkus faster in the Developer Sandbox for Red Hat OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/28/build-your-first-java-serverless-function-using-quarkus-quick-start"&gt;Build your first Java serverless function using a Quarkus quick start&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/10/11/quarkus-spring-developers-kubernetes-native-design-patterns"&gt;Quarkus for Spring developers: Kubernetes-native design patterns&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/07/03/managing-java-containers-quarkus-and-podman-desktop" title="Managing Java containers with Quarkus and Podman Desktop"&gt;Managing Java containers with Quarkus and Podman Desktop&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Kevin Dubois</dc:creator><dc:date>2023-07-03T07:00:00Z</dc:date></entry><entry><title type="html">This Week in JBoss - July 03, 2023</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2023-07-03.html" /><category term="jboss" /><category term="farewell" /><author><name>Don Naro</name><uri>https://www.jboss.org/people/don-naro</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2023-07-03.html</id><updated>2023-07-03T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="jboss, farewell"&gt; &lt;h1&gt;This Week in JBoss - July 03, 2023&lt;/h1&gt; &lt;p&gt;Hello to our dear JBoss community. We, the editorial team, have noticed a downward trend in our readership and have made the decision to no longer carry on. There are many great blogs out there and the JBoss community of projects is producing a lot of great content for you to learn from. However, with the steady decline in our editorial views, we no longer feel the effort we put into distilling the blogs and tutorials is having the sort of impact that we would hope. Writing up the editorials is more work than you might expect and takes a good chunk of time that we could devote to doing our actual jobs or hacking on code.&lt;/p&gt; &lt;p&gt;It has been a great ride and we wish you all the best. We thought about doing a sort of highlight reel to round up some of our favourite blog posts and moments doing the editorial, but realized probably no one is going to read it. So let’s stop shouting into the void and carry on building cool stuff.&lt;/p&gt; &lt;p&gt;Thanks for everything and goodbye.&lt;/p&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/don-naro.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Don Naro&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Don Naro</dc:creator></entry><entry><title type="html">Introducing the new Serverless Logic Web Tools UI</title><link rel="alternate" href="https://blog.kie.org/2023/06/introducing-the-new-serverless-logic-web-tools-ui.html" /><author><name>Fabrizio Antonangeli</name></author><id>https://blog.kie.org/2023/06/introducing-the-new-serverless-logic-web-tools-ui.html</id><updated>2023-06-30T09:05:37Z</updated><content type="html">We are thrilled to announce the release of a major update for Serverless Logic Web Tools. With this update, we have revamped the user interface (UI) and introduced several new functionalities that enhance the overall user experience. To redesign the UI, we relied on the Patternfly React Components from , ensuring responsive support. INSTALLATION The new Serverless Logic Web Tools is live to let you try the new functionalities. THE NEW REDESIGNED SERVERLESS LOGIC WEB TOOLS Now let’s go through the latest changes: * New Sidebar navigation between sections of the application, improving overall usability. * We have divided the home page into three distinct sections: Overview, Recent Models, and Samples Showcase, providing a clear separation of functionalities and making it easier for users to find the information. * Enhanced Error Page: If a problem occurs with a model or if a model or a workspace is not found, you will now be presented with a visually appealing error message with a detail of what went wrong. New Settings Section: * Redesigned Settings Pages: We have replaced the settings modal with the new Settings section. This change provides a more intuitive interface for users to configure their environment. * Quickstart Guide: Configuring your Serverless ecosystem requires some knowledge and can be difficult at first impact. We implemented an on-page “quickstart guide” that assists users to set up their environment and get started with Web Tools. * New Storage Page: Here, you can completely erase all stored data in your browser, including workspaces, models, and settings. The page provides options to clear IndexedDB, LocalStorage, and Cookies, allowing you to reset specific aspects of the application. Please note that this feature is currently compatible only with Google Chrome. * Now that all the features reached the stable version, we removed the Feature Preview setting. New Recent Models and Workspace Files Pages: * Data Table: The new Recent Models and Workspace Files pages now display data in a tabular format, presenting detailed information about each element in rows. Users can take advantage of various functionalities, including sorting columns, filtering elements by name, using pagination to navigate between pages and choosing the number of elements per page.  * Actions Menu: We have added an actions menu for each row in the table. You can delete elements after confirming the action in a specific modal and download elements (workspaces as ZIP files and models as individual files). * Bulk Actions Menu: After selecting the elements or using the select all checkbox, you can execute a bulk delete action always after confirming your action in a modal dialog. * Workspace Files: The Workspace Files section lists files contained within a workspace. Furthermore, users can create new files using the “New File” menu available on the Editor page. * Real-time Updates: Whenever an element is deleted, renamed, or created in a different browser window, the Recent Models and Workspace Files pages will be updated in real-time, ensuring consistency of the data. New Samples Page: * Imported Samples from KIE Samples Repository: Now the samples are automatically fetched from the repository. This integration offers users a wider collection of updated samples that can serve as inspiration or starting points for their new projects. * Improved Grid view: The Samples page now features pagination, with a grid of nine samples displayed per page, allowing for easier navigation, searching for samples by name and filtering by category. * Sample Image Preview: To provide a closer look at each sample, we have added a magnifying glass button over the sample image to view a larger version of the SVG image. CONCLUSION We have many more exciting improvements coming in the future. The redesigned UI and new functionalities in Serverless Logic Web Tools aim to enhance your workflow creation and management experience. With a more clear separation of sections, improved data presentation, and a wide range of samples, we believe that this update will empower you to create Serverless Workflows and Dashboards. Please join us on our and share your thoughts. We appreciate every single comment and are eager to listen to your feedback. The post appeared first on .</content><dc:creator>Fabrizio Antonangeli</dc:creator></entry><entry><title>ISystemTap: An interactive SystemTap notebook</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/30/isystemtap-interactive-systemtap-notebook" /><author><name>Ryan Goldberg</name></author><id>bf73469e-5859-4263-95c6-a277a732da83</id><updated>2023-06-30T07:00:00Z</updated><published>2023-06-30T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://sourceware.org/systemtap/"&gt;SystemTap&lt;/a&gt; is a tool that streamlines the gathering of real-time information about a running &lt;a href="https://developers.redhat.com/topics/linux/"&gt;Linux&lt;/a&gt; system. It can probe and even modify running processes in both the user and kernel spaces, so you can easily monitor your programs without recompiling and installing tools on your system. It also provides many &lt;em&gt;tapsets&lt;/em&gt;, or prewritten libraries that aid in these tasks.&lt;/p&gt; &lt;p&gt;But to a beginner, SystemTap can be overwhelming, and it can be said that with this great power comes an equally great learning curve. To solve this issue, we've introduced an interactive, beginner-friendly interface called ISystemTap.&lt;/p&gt; &lt;h2&gt;About ISystemTap&lt;/h2&gt; &lt;p&gt;ISystemTap is a &lt;a href="https://jupyter.org/"&gt;Jupyter&lt;/a&gt; kernel that allows for running SystemTap scripts in an easy, incremental way within &lt;a href="https://github.com/jupyterlab/jupyterlab"&gt;Jupyterlab&lt;/a&gt;, a lightweight web-browser-based client for executing IPython notebook format documents. It has been popularized with the IPython and IRkernel kernels for education, data science, and machine learning.&lt;/p&gt; &lt;h2&gt;Getting started&lt;/h2&gt; &lt;p&gt;ISystemTap can run right on your machine or from within a container. To get started, install the latest version of SystemTap, currently version 4.9. You will also need SSH to be running on your machine. If it's not running, start it using systemd:&lt;/p&gt; &lt;p&gt;&lt;code&gt;sudo systemctl start sshd&lt;/code&gt;&lt;/p&gt; &lt;p&gt;The following setup will be done for the root user, but alternatively any user in the &lt;a href="https://www.redhat.com/sysadmin/linux-groups"&gt;groups&lt;/a&gt; stapusr and stapdev can run SystemTap as if with root privileges. In this case, the following would not need to be run with &lt;code&gt;sudo&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;If you don't have an SSH key available for the root user, create one with the default name &lt;code&gt;id_rsa&lt;/code&gt;:&lt;/p&gt; &lt;p&gt;&lt;code&gt;sudo ssh-keygen -t rsa -b 4096&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Then execute &lt;code&gt;sudo stap-jupyter-container --run&lt;/code&gt; to start the container as the root user.&lt;/p&gt; &lt;p&gt;This method uses containers to hold Jupyter and related &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; packages that are not included in our typical Linux distributions. Feel free to follow along with this article's examples in the &lt;code&gt;RedHatBlog.ipynb&lt;/code&gt; or &lt;code&gt;ISystemtap.ipynb&lt;/code&gt; notebook files.&lt;/p&gt; &lt;h2&gt;Example: Hello ISystemTap&lt;/h2&gt; &lt;p&gt;At its core, ISystemTap, like all Jupyter notebooks, is a collection of cells. We further introduce the concept of combining groups of cells under a common namespace, which allows cells to share information amongst themselves.&lt;/p&gt; &lt;p&gt;The best way to show this is using an example. Take the following 3 cells in the helloworld namespace:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;%%edit helloworld global ns probe begin {   println("Hello ISystemtap")   ns = module_name() }&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code&gt;%%edit helloworld probe oneshot{   printf("I am the namespace %s\n", ns) }&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code&gt;%%run helloworld&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Cell Output 1: Running the helloworld namespace:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;Hello ISystemTap &lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;I am the namespace helloworld&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Executing the first 2 edit cells will add them to the helloworld namespace, with the first cell defining a &lt;code&gt;begin&lt;/code&gt; probe-point and a global called &lt;code&gt;ns&lt;/code&gt;, and the second defining a &lt;code&gt;oneshot&lt;/code&gt; probe-point. Executing the run cell will stitch the edit cells together in the order in which they were executed and run them as a SystemTap script. Notice that &lt;code&gt;ns&lt;/code&gt; was defined in the first cell but can be used in the second.&lt;/p&gt; &lt;h3&gt;The power of Python&lt;/h3&gt; &lt;p&gt;ISystemTap replaces SystemTap's &lt;a href="https://sourceware.org/systemtap/examples/process/cycle_thief.txt"&gt;ASCII histograms&lt;/a&gt; with rich inline figures, allowing the user to get interactive graphics right alongside the rest of the output. Take the following example, which also introduces the script cell, a cell that combines an edit cell and a run cell:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;%%script histogram global accumulator global i = 0 probe timer.ms(100){   printf("ping %d\n", i)   accumulator &lt;&lt;&lt; randint(i*64+32)   if (i++ &gt; 10)     exit() } probe end{   println("Printing Histogram")   println(@hist_log(accumulator))   print("All done\n") }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The cell 2 output is illustrated in Figure 1.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/histogram.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/histogram.png?itok=72-7dUbP" width="600" height="313" alt="Cell Output 2: Running the histogram namespace" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: Cell output 2: Running the histogram namespace.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;ISystemTap also introduces the python cell, which takes the defined globals from a completed namespace and lets the user access them with Python code. This allows the user to pipeline system information directly into data manipulation tools like &lt;a href="https://numpy.org/"&gt;numpy&lt;/a&gt; and &lt;a href="https://pandas.pydata.org/"&gt;pandas&lt;/a&gt; as well as visualization tools like &lt;a href="https://bqplot.readthedocs.io/en/latest/"&gt;bqplot&lt;/a&gt;. The globals are defined as Python global variables and can be accessed in the same way as any other Python data:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;%%python histogram print(f'{accumulator = }') print(f'{i = }') print(f'{i == accumulator["@count"] = }')&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Cell Output 3: Running a Python cell in the histogram namespace:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;accumulator = {'@count': 11, '@min': 14, '@max': 390, '@sum': 2189, '@avg': 199}&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;i = 11&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;i == accumulator["@count"] = True&lt;/code&gt;&lt;/p&gt; &lt;h3&gt;Monitoring the state&lt;/h3&gt; &lt;p&gt;ISystemTap doesn't just provide cells for the user; it also provides a new interface for SystemTap in the form of a control widget. This widget gives the user data about the namespace's current state, such as its runtime and how much memory it is using (see Figure 2).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/controls_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/controls_0.png?itok=kVUNTmUd" width="429" height="141" alt="The ISystemTap control widget with memory information." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: A control widget of a namespace that completed in 1 second.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Additionally, ISystemTap provides a panel for pausing some or all probes as well as resetting globals to their initial states. The control widget further lets the user see the current values of the various globals as well as some metrics about the probe points. Astute readers might recognize this as the SystemTap monitor mode, which is available without ISystemTap as &lt;code&gt;stap --monitor&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Writing SystemTap scripts&lt;/h2&gt; &lt;p&gt;Thus far, we've talked about running existing scripts, but now we'll discuss a new powerful feature for writing scripts: the SystemTap &lt;a href="https://langserver.org/"&gt;Language Server&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;A language server aims to solve the MxN complexity problem of adding useful language development features, such as code completion, to various editors. Instead of each language having a unique editor-specific interface for its particular implementation (e.g., python-vscode, python-vim, python-emacs), there is one language server implementation that can communicate with many language server clients, one for each editor, reducing the complexity to M+N. The SystemTap Language Server supports code completion and has been tested with many popular editors such as VS Code, Vim, Emacs, and Jupyterlab.&lt;/p&gt; &lt;p&gt;SystemTap code completion covers many common actions one might need when writing scripts. It will complete probe points, functions, and globals from the current script and library tapsets. It will also complete macros, strings, and even context variables within relevant probe points, providing documentation as possible. It is worth noting that the language server is built upon a &lt;a href="https://sourceware.org/git/?p=systemtap.git;a=tree;f=language-server"&gt;custom C++ SDK&lt;/a&gt; which can be used for the creation of other language servers in C++.&lt;/p&gt; &lt;p&gt;Installation is straightforward, with a comprehensive &lt;a href="https://sourceware.org/git/?p=systemtap.git;a=blob;f=language-server/README.md"&gt;guide&lt;/a&gt; with the required manual configuration steps provided in the SystemTap documentation. ISystemTap's install script includes these steps.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Check out our interactive demo to try all of these features and a few others, including a new interface to the SystemTap example scripts and a widget that lists all the probe points that match a user input. Both ISystemTap and the language server are included in SystemTap 4.9.&lt;/p&gt; &lt;p&gt;If you encounter any issues or have any feedback about either of these, please feel free to reach out to us at &lt;a href="mailto:systemtap@sourceware.org"&gt;systemtap@sourceware.org&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/30/isystemtap-interactive-systemtap-notebook" title="ISystemTap: An interactive SystemTap notebook"&gt;ISystemTap: An interactive SystemTap notebook&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Ryan Goldberg</dc:creator><dc:date>2023-06-30T07:00:00Z</dc:date></entry><entry><title type="html">Survey - Cross-Site Replication in Keycloak</title><link rel="alternate" href="https://www.keycloak.org/2023/06/crossdc-survey" /><author><name>Stian Thorgersen</name></author><id>https://www.keycloak.org/2023/06/crossdc-survey</id><updated>2023-06-30T00:00:00Z</updated><content type="html">The Keycloak and Infinispan engineering teams are working together to bring Cross-Site Replication (CSR) to a fully supported state in future Keycloak releases, with Active/Passive support and Active/Active support. We would like to gather inputs on your expectations, requirements, use-cases and sizing of the target deployment environments for the CSR feature. Thanks in advance for filling out this survey form to help us better plan and deliver this feature. If your are interested in Active/Passive or Active/Active deployments of Keycloak please fill in .</content><dc:creator>Stian Thorgersen</dc:creator></entry><entry><title>How to develop and deploy OpenShift console dynamic plugin</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/29/how-develop-and-deploy-openshift-console-dynamic-plugin" /><author><name>Ajay Pratap</name></author><id>bd9a9000-fb9e-437c-b1c5-986aa4c56de0</id><updated>2023-06-29T07:00:00Z</updated><published>2023-06-29T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://github.com/openshift/console/tree/master/frontend/packages/console-dynamic-plugin-sdk"&gt;Dynamic plugins&lt;/a&gt; allow you to extend the &lt;a href="https://github.com/openshift/console"&gt;Red Hat OpenShift UI&lt;/a&gt; at runtime, adding custom pages and other extensions. They are based on the &lt;a href="https://webpack.js.org/concepts/module-federation/"&gt;webpack module federation&lt;/a&gt;. Plugins are registered with the console using the &lt;code&gt;ConsolePlugin&lt;/code&gt; custom resource and enabled in the console operator config by a cluster administrator.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://nodejs.org/en/"&gt;Node.js&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://yarnpkg.com/"&gt;yarn&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; or &lt;a href="https://podman.io/"&gt;podman 3.2.0+&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://console.redhat.com/openshift/downloads"&gt;oc&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Getting started&lt;/h2&gt; &lt;p&gt;To clone &lt;a href="https://github.com/openshift/console-plugin-template"&gt;console plugin template repo&lt;/a&gt;, you should update the plugin metadata, such as the plugin name in the &lt;code&gt;ConsolePlugin &lt;/code&gt; declaration of package.json.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-javascript"&gt;"consolePlugin": {   "name": "plugin-name",   "version": "0.0.1",   "displayName": "Dynamic Plugin",   "description": "OpenShift console dynamic plugin",   "exposedModules": {     "ExamplePage": "./components/ExamplePage"   },   "dependencies": {     "@console/pluginAPI": "*"   } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The template adds a single example page in the home navigation section. The extension is in the &lt;a href="https://github.com/openshift/console-plugin-template/blob/main/console-extensions.json"&gt;console-extensions.json&lt;/a&gt; file and the react component is declared in: src/components/ExamplePage.tsx.&lt;/p&gt; &lt;p&gt;You can run the plugin using a local development environment or build an image to deploy it to a cluster.&lt;/p&gt; &lt;p&gt;There are two ways for development.&lt;/p&gt; &lt;h3&gt;Development option 1: Local&lt;/h3&gt; &lt;p&gt;In the terminal window, run the following commands:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;yarn install&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;yarn run start&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;In another terminal window, run these commands:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;oc login&lt;/code&gt; (requires &lt;a href="https://console.redhat.com/openshift/downloads"&gt;oc&lt;/a&gt; and an &lt;a href="https://console.redhat.com/openshift/create"&gt;OpenShift cluster&lt;/a&gt;)&lt;/li&gt; &lt;li&gt;&lt;code&gt;yarn run start-console&lt;/code&gt; (requires &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; or &lt;a href="https://podman.io/"&gt;Podman 3.2.0+&lt;/a&gt;)&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;This will run the OpenShift console in a container connected to the cluster you logged into. The plugin HTTP server runs on port 9001 with CORS enabled. Navigate to http://localhost:9000/example to see the running plugin.&lt;/p&gt; &lt;h3&gt;Running start-console with Apple silicon and Podman&lt;/h3&gt; &lt;p&gt;If you are using podman on a Mac with Apple silicon, &lt;code&gt;yarn run start-console&lt;/code&gt; might fail since it runs an amd64 image. You can workaround the problem with &lt;a href="https://github.com/multiarch/qemu-user-static"&gt;qemu-user-static&lt;/a&gt; by running these commands:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman machine ssh sudo -i rpm-ostree install qemu-user-static systemctl reboot&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note: If you are facing issues related to tls while oc loggedIn, skip tls by adding below flag &lt;code&gt;--insecure-skip-tls-verify=true&lt;/code&gt; with oc loggedIn command.&lt;/p&gt; &lt;p&gt;&lt;code&gt;oc login -u kubeadmin -p &lt;password&gt; --insecure-skip-tls-verify=true&lt;/code&gt;&lt;/p&gt; &lt;h3&gt;Development option 2: Docker and VSCode remote containers&lt;/h3&gt; &lt;p&gt;Make sure the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers"&gt;remote containers&lt;/a&gt; extension is installed. This method uses Docker Compose where one container is the OpenShift console and the second container is the plugin. It requires that you have access to an existing OpenShift cluster. After the initial build, the cached containers will help you start developing in seconds.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Create a &lt;code&gt;dev.env&lt;/code&gt; file inside the &lt;code&gt;.devcontainer&lt;/code&gt; folder with the correct values for your cluster:&lt;/li&gt; &lt;/ul&gt;&lt;pre&gt; &lt;code class="language-bash"&gt;OC_PLUGIN_NAME=my-plugin OC_URL=https://api.example.com:6443 OC_USER=kubeadmin OC_PASS=&lt;password&gt;&lt;/code&gt;&lt;/pre&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;(Ctrl+Shift+P) =&gt; Remote Containers: Open Folder in Container...&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;yarn run start&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Navigate to: http://localhost:9000/example&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Build the docker image&lt;/h2&gt; &lt;p&gt;You can deploy your plugin on a cluster. You must build an image and push it to an image registry. Create an account for Red Hat &lt;a href="https://quay.io/"&gt;Quay.io&lt;/a&gt;.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Build the image:&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;&lt;code&gt;docker build -t quay.io/my-repositroy/my-plugin:latest.&lt;/code&gt;&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Run the image:&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;&lt;code&gt;docker run -it --rm -d -p 9001:80 quay.io/my-repository/my-plugin:latest&lt;/code&gt;&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Push the image:&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;&lt;code&gt;docker push quay.io/my-repository/my-plugin:latest&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Note: If you have a Mac with Apple silicon, you will need to add the flag &lt;code&gt;--platform=linux/amd64&lt;/code&gt; when building the image to target the correct platform to run in-cluster.&lt;/p&gt; &lt;h2&gt;Deployment on the cluster&lt;/h2&gt; &lt;p&gt;Download the &lt;a href="https://github.com/openshift/console-plugin-template/blob/example-pod-tab/template.yaml"&gt;yaml template&lt;/a&gt; file and update plugin name &lt;code&gt;PLUGIN_NAME&lt;/code&gt; , namespace &lt;code&gt;NAMESPACE&lt;/code&gt;, docker image &lt;code&gt;IMAGE&lt;/code&gt; etc.&lt;/p&gt; &lt;p&gt;You can deploy the plugin to a cluster by applying &lt;code&gt;template.yaml.&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;oc apply -f template.yaml&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Once deployed, patch the &lt;a href="https://github.com/openshift/console-operator"&gt;console operator&lt;/a&gt; config to enable the plugin.&lt;/p&gt; &lt;pre&gt; &lt;code&gt;oc patch consoles.operator.openshift.io cluster --patch '{ "spec": { "plugins": ["plugin-name"] } }' --type=merge&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Deployment by Helm chart&lt;/h2&gt; &lt;p&gt;A &lt;a href="https://helm.sh/"&gt;Helm&lt;/a&gt; chart is available to deploy the plugin to an OpenShift environment.&lt;/p&gt; &lt;p&gt;The following Helm parameters are required:&lt;/p&gt; &lt;p&gt;&lt;code&gt;plugin.image&lt;/code&gt;: The location of the image containing the plugin that was previously pushed.&lt;/p&gt; &lt;p&gt;Additional parameters can be specified if desired. Consult the chart &lt;a href="https://github.com/openshift/console-plugin-template/blob/main/charts/openshift-console-plugin/values.yaml"&gt;values&lt;/a&gt; file for the full set of supported parameters.&lt;/p&gt; &lt;h3&gt;Installing the Helm chart&lt;/h3&gt; &lt;p&gt;Install the chart using the name of the plugin as the Helm release name into a new namespace or an existing namespace as specified by the &lt;code&gt;my-plugin-namespace&lt;/code&gt; parameter and providing the location of the image within the &lt;code&gt;plugin.image&lt;/code&gt; parameter by using the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;helm upgrade -i my-plugin charts/openshift-console-plugin -n my-plugin-namespace --create-namespace --set plugin.image=my-plugin-image-location&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note: When deploying on OpenShift 4.10, it is recommended to add the parameter &lt;code&gt;--set plugin.securityContext.enabled=false&lt;/code&gt; which will omit configurations related to pod security.&lt;/p&gt; &lt;h2&gt;Learn more about the OpenShift console plugin&lt;/h2&gt; &lt;p&gt;This article guided you through getting started in the dynamic plugin for &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;. For more information, refer to the &lt;a href="https://github.com/openshift/console/tree/master/frontend/packages/console-dynamic-plugin-sdk"&gt;Console Plugin SDK README&lt;/a&gt; and &lt;a href="https://github.com/artemiscloud/activemq-artemis-self-provisioning-plugin"&gt;ActiveMQ Artemis Self Provisioning Plugin&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/29/how-develop-and-deploy-openshift-console-dynamic-plugin" title="How to develop and deploy OpenShift console dynamic plugin"&gt;How to develop and deploy OpenShift console dynamic plugin&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Ajay Pratap</dc:creator><dc:date>2023-06-29T07:00:00Z</dc:date></entry><entry><title>Quarkus 3.1.3.Final released - Maintenance release</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-3-1-3-final-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-3-1-3-final-released/</id><updated>2023-06-29T00:00:00Z</updated><published>2023-06-29T00:00:00Z</published><summary type="html">We released Quarkus 3.1.3.Final, the third maintenance release of our 3.1 release train. As usual, it contains bugfixes and documentation improvements. It should be a safe upgrade for anyone already using 3.1. If you are not already using 3.1, please refer to the Quarkus 3.1 migration guide. And if you...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2023-06-29T00:00:00Z</dc:date></entry></feed>
