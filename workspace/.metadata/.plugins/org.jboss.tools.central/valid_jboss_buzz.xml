<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>What's new in Ansible Automation Platform 2.4</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/27/ansible-automation-platform-whats-new" /><author><name>Himanshu Yadav</name></author><id>dcee9416-fcb2-4200-ba75-df414ff7a792</id><updated>2023-06-27T13:35:00Z</updated><published>2023-06-27T13:35:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Red Hat Ansible Automation Platform 2.4&lt;/a&gt; is generally available (GA). It is a simple, agentless &lt;a href="https://developers.redhat.com/topics/automation"&gt;automation&lt;/a&gt; platform that improves your current processes, integrates event-driven automation, and provides a sneak peek at how artificial intelligence (AI) will improve automation in the future. This article describes the new features you'll find in &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Ansible Automation Platform 2.4&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Event-Driven Ansible&lt;/h2&gt; &lt;p&gt;Announced as developer preview during AnsibleFest 2022, Event-Driven Ansible is now available with Ansible Automation Platform 2.4. Event-Driven Ansible is a scalable, responsive automation capability that processes events containing discrete, actionable intelligence. It empowers teams to determine the appropriate response to an event and execute automated actions to address or remediate it.&lt;/p&gt; &lt;p&gt;Event-Driven Ansible frees teams from mundane tasks to focus on innovation while enabling more responsive and resilient IT services through the faster resolution of requests. It can work with multiple data sources and trigger required actions automatically. You can incorporate Event-Driven Ansible to any use case, such as networking, infrastructure, security, edge, cloud, application automation, and beyond.&lt;/p&gt; &lt;p&gt;Refer to our &lt;a href="https://www.redhat.com/en/resources/5-ways-event-driven-automation-checklist?sc_cid=7013a000003SdMpAAK"&gt;checklist&lt;/a&gt; on how event-driven automation can help you achieve more.&lt;/p&gt; &lt;h2&gt;Validated content integration&lt;/h2&gt; &lt;p&gt;Ansible validated content is now available through &lt;a href="https://console.redhat.com/ansible/ansible-dashboard"&gt;Ansible automation hub&lt;/a&gt; and validated content collections are also pre-loaded into private automation hub. Validated content is curated by Red Hat and can be customized for customers' unique environments. Validated content is available for use cases such as infrastructure, infrastructure at the edge, security, networking, network at the edge, and hybrid cloud.&lt;/p&gt; &lt;h2&gt;Platform install support for ARM&lt;/h2&gt; &lt;p&gt;If your infrastructure has ARM requirements, you can now install the full Ansible Automation Platform on &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; just as you would with x86 systems. This allows you to use Ansible seamlessly on edge devices and keep them in compliance with all other sites in your full infrastructure.&lt;/p&gt; &lt;h2&gt;Technology preview features&lt;/h2&gt; &lt;p&gt;There are several features that are part of Ansible Automation Platform 2.4 as &lt;a href="https://access.redhat.com/support/offerings/techpreview?sc_cid=7013a000003SdMpAAK"&gt;technology preview&lt;/a&gt;. These changes are not yet fully supported by Red Hat but allow us to test and provide feedback for future capabilities.&lt;/p&gt; &lt;h3&gt;Ansible Lightspeed with IBM Watson Code Assistant&lt;/h3&gt; &lt;p&gt;Ansible Lightspeed with IBM Watson Code Assistant is a generative AI service accessed via the Ansible Visual Studio Code extension. This service lets you accept and run recommended code directly into your code editing environment while creating Ansible playbooks. Simply type a task in plain English into the VS Code editor, and it will make a code recommendation for you to consider.&lt;/p&gt; &lt;p&gt;You can accept, reject, and modify the code and provide feedback on the recommendations in this technology preview. Register &lt;a href="http://redhat.com/ansible-lightspeed?sc_cid=7013a000003SdMpAAK"&gt;here&lt;/a&gt; to receive Ansible Lightspeed technology preview notifications and experience the generative AI experience.&lt;/p&gt; &lt;h3&gt;Centralized user interface&lt;/h3&gt; &lt;p&gt;As Ansible Automation Platform continues to evolve the user experience, several new UI features are in technology preview in Ansible 2.4. There are new views in the automation controller, including night mode and system default setting matching. On-premise analytics reports are also available directly in the automation controller with new UI.&lt;/p&gt; &lt;p&gt;To find out more, check out this quick &lt;a href="https://www.youtube.com/watch?v=IBtGCQBkM0A"&gt;demo&lt;/a&gt; on how to enable new UI features for Ansible Automation Platform 2.4.&lt;/p&gt; &lt;h3&gt;Automation controller installation support for Linux on Power and Z&lt;/h3&gt; &lt;p&gt;Organizations that utilize power-based systems or have mainframes that require strict management separation from the infrastructure  can install the automation controller and have the ability to automate their environments completely separately from the rest of their infrastructure.&lt;/p&gt; &lt;h2&gt;Make the move to Ansible Automation Platform 2.4&lt;/h2&gt; &lt;p&gt;You can &lt;a href="https://developers.redhat.com/products/ansible/download"&gt;download the latest version of the Ansible Automation Platform&lt;/a&gt; at no cost.&lt;a href="https://developers.redhat.com/products/ansible/getting-started"&gt; Get started&lt;/a&gt; with the Ansible Automation Platform by exploring interactive labs.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/27/ansible-automation-platform-whats-new" title="What's new in Ansible Automation Platform 2.4"&gt;What's new in Ansible Automation Platform 2.4&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Himanshu Yadav</dc:creator><dc:date>2023-06-27T13:35:00Z</dc:date></entry><entry><title>How to deploy apps in a K8s cluster via automation controller</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/26/how-deploy-apps-k8s-cluster-automation-controller" /><author><name>Nagesh Rathod</name></author><id>92ce2ab7-2ec3-4eeb-b409-bb09e34dc3dd</id><updated>2023-06-26T07:00:00Z</updated><published>2023-06-26T07:00:00Z</published><summary type="html">&lt;p&gt;This article demonstrates how to deploy gaming applications in a &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; (K8s) cluster using &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Red Hat Ansible Automation Platform&lt;/a&gt;. The minikube cluster is the best single node cluster for a personal POC. For this article, we will use a minikube cluster and Ansible Automation Platform 2.3 and a restricted set of privileges in the cluster to deploy the application in &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. &lt;a href="https://developers.redhat.com/topics/automation"&gt;Automation&lt;/a&gt; and orchestration are a rock solid combination that yield more promising results.&lt;/p&gt; &lt;h2&gt;How to start minikube&lt;/h2&gt; &lt;p&gt;Make sure you have &lt;a href="https://kubernetes.io/docs/tasks/tools/"&gt;kubectl&lt;/a&gt; and &lt;a href="https://minikube.sigs.k8s.io/docs/start/"&gt;minikube&lt;/a&gt; CLI installed before getting started with the Kubernetes cluster.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ minikube start 😄  minikube v1.26.1 on Redhat 9.1 ❗  Specified Kubernetes version 1.25.7 is newer than the newest supported version: v1.24.3. Use `minikube config defaults kubernetes-version` for details. ✨  Using the docker driver based on existing profile 👍  Starting control plane node minikube in cluster minikube 🚜  Pulling base image... 🔄  Restarting existing docker container for "minikube"... 🐳  Preparing Kubernetes v1.25.7 on Docker 20.10.17... 🔎  Verifying Kubernetes components...     ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5     ▪ Using image kubernetesui/dashboard:v2.6.0     ▪ Using image kubernetesui/metrics-scraper:v1.0.8 🌟  Enabled addons: storage-provisioner, default-storageclass, dashboard 🏄  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Check to see if the cluster is up and running, as follows:&lt;/p&gt; &lt;div&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ kubectl get nodes NAME       STATUS   ROLES           AGE    VERSION minikube   Ready    control-plane   2d5h   v1.25.7&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;h2&gt;Install and configure Ansible Automation Platform&lt;/h2&gt; &lt;p&gt;First, &lt;a href="https://developers.redhat.com/articles/2023/01/01/how-install-red-hat-ansible-automation-platform-rhel-9#"&gt;install&lt;/a&gt; the Ansible Automation Platform on your server or system.&lt;/p&gt; &lt;p&gt;Then, go to &lt;code&gt;http://localhost&lt;/code&gt; in your browser to access the Ansible Automation Platform console.&lt;/p&gt; &lt;h3&gt;5 steps to interact with Kubernetes cluster&lt;/h3&gt; &lt;h4&gt;Step 1: Set up Kubernetes cluster credentials&lt;/h4&gt; &lt;p&gt;Credentials are utilized for authentication when launching jobs against machines, synchronizing with inventory sources, and importing project content from a version control system.&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;From the Ansible Automation Platform console left menu, select &lt;strong&gt;Credentials&lt;/strong&gt; (Figure 1).&lt;/li&gt; &lt;li aria-level="1"&gt;Click on &lt;strong&gt;Add&lt;/strong&gt; and enter a name for the credentials.&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/1_3.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/1_3.png?itok=Ih1rQmkK" width="600" height="296" alt="A screenshot of the credential page of Ansible." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: Adding the Kubernetes cluster credentials.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;For the credential type (1), select &lt;strong&gt;Kubernetes or Kubernetes API Bearer Token&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Select your organization.&lt;/li&gt; &lt;li&gt;Enter the OpenShift or Kubernetes API Endpoint (2):&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Provide the endpoint of the minikube cluster to which you want to deploy the application.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ minikube ip 192.168.49.2&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The minikube cluster endpoint:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;https://192.168.49.2:8443&lt;/code&gt;&lt;/pre&gt; &lt;ul&gt;&lt;li&gt;For the token and certificate fields, we need to create a &lt;code&gt;ServiceAccount&lt;/code&gt;, &lt;code&gt;Role&lt;/code&gt;, &lt;code&gt;RoleBinding&lt;/code&gt; and &lt;code&gt;Secret&lt;/code&gt;. Please apply the following context in your Kubernetes cluster.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Make sure you have a cluster admin access.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;cat &lt;&lt;EOF | kubectl apply -f - --- apiVersion: v1 kind: Namespace metadata:   name: dev-game-app ---   apiVersion: v1   kind: ServiceAccount   metadata:       annotations:       name: containergroup-service-account       namespace: dev-game-app ---   kind: Role   apiVersion: rbac.authorization.k8s.io/v1   metadata:     name: role-containergroup-service-account     namespace: dev-game-app   rules:   - apiGroups: ["*"]     resources: ["*"]     verbs: ["*"] ---   kind: RoleBinding   apiVersion: rbac.authorization.k8s.io/v1   metadata:     name: role-containergroup-service-account-binding     namespace: dev-game-app   subjects:   - kind: ServiceAccount     name: containergroup-service-account   roleRef:     kind: Role     name: role-containergroup-service-account     apiGroup: rbac.authorization.k8s.io --- apiVersion: v1 kind: Secret type: kubernetes.io/service-account-token metadata:   name: cicd   namespace: dev-game-app   annotations:     kubernetes.io/service-account.name: "containergroup-service-account" EOF&lt;/code&gt;&lt;/pre&gt; &lt;ul&gt;&lt;li&gt;Enter the&lt;strong&gt; API authentication bearer token &lt;/strong&gt;(3):&lt;/li&gt; &lt;/ul&gt;&lt;pre&gt; &lt;code class="language-bash"&gt;$ kubectl get secret cicd -n dev-game-app -o json | jq '.data.token' | xargs | base64 --decode &gt; containergroup-sa.token&lt;/code&gt;&lt;/pre&gt; &lt;div&gt; &lt;table cellspacing="0" width="0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt; &lt;p&gt;This command creates a file named &lt;code&gt;containergroup-sa.token&lt;/code&gt;.&lt;em&gt; &lt;/em&gt;Copy the token context and paste it in the Ansible Automation Platform console.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Enter the&lt;strong&gt; Certificate Authority data&lt;/strong&gt; (4).&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Extract the certificate from the cluster by using the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ kubectl get secret cicd -n dev-game-app -o json | jq '.data["ca.crt"]' | xargs | base64 --decode &gt; containergroup-ca.crt&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This creates a file named &lt;code&gt;containergroup-ca.crt&lt;/code&gt; which you must copy and paste into the Ansible Automation Platform console and then save it.&lt;/p&gt; &lt;h4&gt;Step 2: Configure the container and instance groups&lt;/h4&gt; &lt;p&gt;To configure the instance group, navigate to the instance group and create a &lt;strong&gt;Container group&lt;/strong&gt;, as shown in Figure 2.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Provide a name for the container group and select recently created credentials.&lt;/li&gt; &lt;li&gt;Select the recently created credentials (1).&lt;/li&gt; &lt;li&gt;Tick the box for the &lt;strong&gt;Customize pod specification&lt;/strong&gt; under options (2).&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Expand&lt;/strong&gt; button (3).&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/2_6.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/2_6.png?itok=jwCVqkoa" width="600" height="296" alt="Adding the instance group for the execution pod." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: Adding the instance group for the execution pod.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;We have already created the resources in the cluster in the credentials section, so we just need to update it as follows (Figure 3):&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Update the name of &lt;strong&gt;namespace &lt;/strong&gt;(3.1).&lt;/li&gt; &lt;li&gt;Update the &lt;strong&gt;serviceAccountName &lt;/strong&gt;(3.2).&lt;/li&gt; &lt;li&gt;The &lt;strong&gt;imagePullSecrets&lt;/strong&gt; is not part of the default context (3.3).&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/3_8.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/3_8.png?itok=OAPWu8By" width="600" height="373" alt="A screenshot of the pod manifest." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: Updating the Namespace, ServiceAccount, and ImangePullSecrets.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;Create the imagePullSecrets we defined in (3.3). Make sure you have an account on registry.redhat.io. Using the following command, you can create a secret easily in the Kubernetes cluster:&lt;/li&gt; &lt;/ul&gt;&lt;pre&gt; &lt;code class="language-bash"&gt;$ kubectl create secret docker-registry regcred --docker-server=registry.redhat.io --docker-username='foouser@xyz.com' --docker-password='123@Redhat' -n dev-game-app&lt;/code&gt;&lt;/pre&gt; &lt;h4&gt;Step 3: Add inventories&lt;/h4&gt; &lt;p&gt;An &lt;a href="https://docs.ansible.com/automation-controller/latest/html/userguide/glossary.html#term-Inventory"&gt;inventory&lt;/a&gt; is a collection of hosts against which jobs can be launched, the same as an Ansible inventory file.&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;From the left menu, select &lt;strong&gt;Inventories&lt;/strong&gt; (Figure 4).&lt;/li&gt; &lt;li aria-level="1"&gt;Click on &lt;strong&gt;Add&lt;/strong&gt; button and select &lt;strong&gt;Add Inventories&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Enter a name to the inventory.&lt;/li&gt; &lt;li aria-level="1"&gt;Next, add the &lt;strong&gt;host&lt;/strong&gt; to the inventory. We are using localhost. Copy and paste the following context in variable section:&lt;/li&gt; &lt;/ul&gt;&lt;pre&gt; &lt;code class="language-bash"&gt;​​​​​​​--- {'ansible_host': '127.0.0.1', 'ansible_connection': 'local'}&lt;/code&gt;&lt;/pre&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/4_5.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/4_5.png?itok=BzqHked5" width="600" height="294" alt="A screenshot of the inventory page in Ansible." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: Adding the host in inventories.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li aria-level="1"&gt;Finally, test the connectivity with the Kubernetes cluster using the &lt;strong&gt;ping&lt;/strong&gt; module by clicking the &lt;strong&gt;Run Command&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Select the &lt;strong&gt;Run Command&lt;/strong&gt; first.&lt;/li&gt; &lt;li&gt;Select the &lt;strong&gt;ping&lt;/strong&gt; module from the dropdown and choose &lt;strong&gt;Demo Credentials&lt;/strong&gt;. &lt;/li&gt; &lt;li&gt;Keep the rest of the details as default (you can change the settings per your environment requirement).&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Launch&lt;/strong&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The job results are as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;kube-deploy-host | SUCCESS =&gt; {     "ansible_facts": {         "discovered_interpreter_python": "/usr/libexec/platform-python"     },     "changed": false,     "ping": "pong" }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This validates that the cluster details, such as the endpoints and credentials, are correct.&lt;/p&gt; &lt;h4&gt;Step 4:&lt;strong&gt; &lt;/strong&gt;Create a project&lt;/h4&gt; &lt;p&gt;A project is a logical collection of Ansible Playbooks, represented in the automation controller. You can manage playbooks and playbook directories by either placing them manually under the project base path on your controller server, or by placing your playbooks into a source code management (SCM) system supported by the automation controller, including Git, Subversion, and Mercurial.&lt;/p&gt; &lt;p&gt;You can use this repo as well:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Create a&lt;strong&gt; new projec&lt;/strong&gt;t for our Git repository from the left menu.&lt;/li&gt; &lt;li aria-level="1"&gt;Click on the &lt;strong&gt;+&lt;/strong&gt; icon from the right corner.&lt;/li&gt; &lt;li aria-level="1"&gt;Give project a name.&lt;/li&gt; &lt;li aria-level="1"&gt;Select your organization.&lt;/li&gt; &lt;li aria-level="1"&gt;Select the SCM TYPE (GIT, in our case).&lt;/li&gt; &lt;li aria-level="1"&gt;Add RESOURCE DETAILS &lt;ul&gt;&lt;li aria-level="2"&gt;5.4.1. SCM URL.&lt;/li&gt; &lt;li aria-level="2"&gt;5.4.2. SCM BRANCH.&lt;/li&gt; &lt;li aria-level="2"&gt;5.4.3. SCM CREDENTIAL. &lt;ul&gt;&lt;li aria-level="3"&gt;Click on &lt;strong&gt;+&lt;/strong&gt; it to create new credentials.&lt;/li&gt; &lt;li aria-level="3"&gt;Give credentials a name.&lt;/li&gt; &lt;li aria-level="3"&gt;Select organization.&lt;/li&gt; &lt;li aria-level="3"&gt;Select the credentials type and file accordingly.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li aria-level="2"&gt;5.4.4. Save it.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h4&gt;Step 5:&lt;strong&gt;  &lt;/strong&gt;Create job templates&lt;/h4&gt; &lt;p&gt;A &lt;a href="https://docs.ansible.com/automation-controller/latest/html/userguide/glossary.html#term-Job-Template"&gt;job template&lt;/a&gt; is a definition and set of parameters for running an Ansible job. Job templates are useful to execute the same job many times. Job templates also encourage the reuse of Ansible Playbook content and collaboration between teams.&lt;/p&gt; &lt;p&gt;Create a template that will execute the job for us.&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;From the left menu, select templates and create a &lt;strong&gt;new template&lt;/strong&gt; (Figure 5).&lt;/li&gt; &lt;li aria-level="1"&gt;Click on &lt;strong&gt;+&lt;/strong&gt; icon from the right corner and select the &lt;strong&gt;Job template&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Give the template a name (1).&lt;/li&gt; &lt;li aria-level="1"&gt;Select the &lt;strong&gt;inventory&lt;/strong&gt; (2).&lt;/li&gt; &lt;li aria-level="1"&gt;Select a &lt;strong&gt;Project &lt;/strong&gt;(3).&lt;/li&gt; &lt;li aria-level="1"&gt;Choose the &lt;strong&gt;playbook&lt;/strong&gt; you want to run in the template. &lt;a href="https://github.com/redhat-developer-demos/ansible-automation-platform-continous-delivery-demo"&gt;GiHub repository&lt;/a&gt; (4).&lt;/li&gt; &lt;li aria-level="1"&gt;Choose &lt;strong&gt;Credentials&lt;/strong&gt; (5).&lt;/li&gt; &lt;li aria-level="1"&gt;Select &lt;strong&gt;Instance group&lt;/strong&gt; (6).&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/5_7.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/5_7.png?itok=g9mDQmxM" width="600" height="296" alt="A screenshot of the templates page in Ansible." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: Creating a template with all dependencies.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt; &lt;/p&gt; &lt;pre&gt; &lt;code&gt;--- - hosts: all - hosts: localhost   collections:   - kubernetes.core   tasks:   - name: Get a list of all pods from any namespace     kubernetes.core.k8s_info:       kind: Pod       namespace: ansible-automation-platform     register: pod_list - name: create k8s pod     kubernetes.core.k8s:       src: deployment.yaml       namespace: dev-game-app       state: present - name: service create     kubernetes.core.k8s:       src: service.yaml       namespace: dev-game-app       state: present &lt;/code&gt;&lt;/pre&gt; &lt;ul&gt;&lt;li&gt;Finally, run the template and verify the result in the cluster.&lt;/li&gt; &lt;/ul&gt;&lt;pre&gt; &lt;code class="language-bash"&gt;$ kubectl get pods -n dev-game-app -w automation-job-267-wvsbx      0/1     Pending             0          0s automation-job-267-wvsbx      0/1     Pending             0          0s automation-job-267-wvsbx      0/1     ContainerCreating   0          0s automation-job-267-wvsbx      1/1     Running             0          10s automation-job-267-wvsbx      1/1     Terminating         0          11s automation-job-267-wvsbx      0/1     Terminating         0          12s automation-job-267-wvsbx      0/1     Terminating         0          13s racing-game-fd795c897-82w87   1/1     Running             0          21s&lt;/code&gt;&lt;/pre&gt; &lt;ul&gt;&lt;li&gt;Do the port-forwarding to test the application.&lt;/li&gt; &lt;/ul&gt;&lt;pre&gt; &lt;code class="language-bash"&gt;$ kubectl port-forward pod/racing-game-fd795c897-82w87 8080:8080 -n dev-game-app Forwarding from 127.0.0.1:8080 -&gt; 8080 Handling connection for 8080 Handling connection for 8080&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Open up the browser and enter &lt;strong&gt;localhost:8080&lt;/strong&gt; to get a glimpse of the gaming application.&lt;/p&gt; &lt;h2&gt;Continue your automation journey&lt;/h2&gt; &lt;p&gt;The goal of this article was to demonstrate how Ansible Automation Platform can be used to deploy gaming applications into Kubernetes clusters. It’s a one-time set up. You can also use the same solution for the managed Kubernetes cloud services like EKS, AKS, GKE, and many more. &lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/ansible/getting-started"&gt;Get started&lt;/a&gt; with the Ansible Automation Platform by exploring &lt;a href="https://developers.redhat.com/products/ansible/getting-started"&gt;interactive labs&lt;/a&gt;. Ansible Automation Platform is also available as a managed offering on&lt;a href="https://www.redhat.com/en/technologies/management/ansible/azure"&gt; Microsoft Azure&lt;/a&gt; and as a self-managed offering on &lt;a href="https://www.redhat.com/en/technologies/management/ansible/aws"&gt;AWS&lt;/a&gt;. &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;Get started&lt;/a&gt; with OpenShift by visiting the &lt;a href="https://developers.redhat.com/developer-sandbox/activities"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;. &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/azure"&gt;Microsoft Azure&lt;/a&gt; and &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/aws"&gt;Amazon Web Services&lt;/a&gt; also offer OpenShift managed services. Explore &lt;a href="https://developers.redhat.com/learn#assembly-id-70181"&gt;interactive lessons&lt;/a&gt; to begin your OpenShift learning journey.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/26/how-deploy-apps-k8s-cluster-automation-controller" title="How to deploy apps in a K8s cluster via automation controller"&gt;How to deploy apps in a K8s cluster via automation controller&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Nagesh Rathod</dc:creator><dc:date>2023-06-26T07:00:00Z</dc:date></entry><entry><title>Quarkus Native with Podman for Windows</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/podman-for-windows/&#xA;            " /><author><name>Karm Michal Babacek (https://twitter.com/_karm)</name></author><id>https://quarkus.io/blog/podman-for-windows/</id><updated>2023-06-26T00:00:00Z</updated><published>2023-06-26T00:00:00Z</published><summary type="html">Developers who use Windows workstations might face the challenge of running Linux-native workflows. One way to achieve this is by using Podman, a container engine that provides a command line capability to run Linux containers. Podman supports running containers both as "rootful" and as "rootless", with the latter being the...</summary><dc:creator>Karm Michal Babacek (https://twitter.com/_karm)</dc:creator><dc:date>2023-06-26T00:00:00Z</dc:date></entry><entry><title>Dev productivity - Quarkus CLI</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-cli/&#xA;            " /><author><name>Ioannis Canellos (https://twitter.com/iocanel)</name></author><id>https://quarkus.io/blog/quarkus-cli/</id><updated>2023-06-23T00:00:00Z</updated><published>2023-06-23T00:00:00Z</published><summary type="html">People hardly realize that the Quarkus CLI was available from the first public release of Quarkus back in 2019. It originally only allowed project creation and extension manipulation. The following command shows the list of supported commands: quarkus --help Usage: quarkus &lt;command&gt; [&lt;args&gt;] These are the common quarkus commands used...</summary><dc:creator>Ioannis Canellos (https://twitter.com/iocanel)</dc:creator><dc:date>2023-06-23T00:00:00Z</dc:date></entry><entry><title>How to create a workspace via Try in Dev Spaces extension</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/22/how-create-workspace-try-dev-spaces-extension" /><author><name>David Kwon</name></author><id>f1be340e-5e44-46ce-9bee-d5eefdcccf6c</id><updated>2023-06-22T07:00:00Z</updated><published>2023-06-22T07:00:00Z</published><summary type="html">&lt;p&gt;In early June, we released a new web extension for Red Hat OpenShift Dev Spaces called &lt;a href="https://redhat-developer.github.io/try-in-dev-spaces-browser-extension/"&gt;Try in Dev Spaces&lt;/a&gt;. Version 1.0 of the extension is available for Chromium-based browsers (Google Chrome, Microsoft Edge, Brave, Opera, etc.), Safari, and Firefox.&lt;/p&gt; &lt;p&gt;You can download the web extension from these marketplaces:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://chrome.google.com/webstore/detail/try-in-dev-spaces/gbookaeilomckmoofeocnkfidfeendan"&gt;Chrome Web Store&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://apps.apple.com/us/app/try-in-dev-spaces/id6446597744"&gt;Mac App Store&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://addons.mozilla.org/en-US/firefox/addon/try-in-dev-spaces/"&gt;Firefox Browser Add-ons&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;How to use the Try in Dev Spaces web extension&lt;/h2&gt; &lt;p&gt;Are you new to OpenShift Dev Spaces? Try it for free in the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This extension provides a &lt;strong&gt;Dev Spaces&lt;/strong&gt; button in the GitHub project page that creates and opens a new workspace with the GitHub project on an OpenShift Dev Spaces installation (Figure 1). OpenShift Dev Spaces is a platform for creating reproducible, container-based cloud development environments (or workspaces) for your Git projects on Red Hat OpenShift. In a workspace, you can code, build, test, and deploy your application within an OpenShift cluster.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/btn-and-dropdown.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/btn-and-dropdown.jpg?itok=q1n9ytN2" width="1100" height="380" alt="The 'Dev Spaces' button within the GitHub UI and the button's dropdown items displaying different Dev Spaces instances/" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1. Screenshots of the extension's Dev Spaces button within the GitHub UI.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;By default the web extension opens the GitHub project on the free OpenShift Dev Spaces instance accessible on the Developer Sandbox for Red Hat OpenShift. However, additional Dev Spaces instances (or upstream Eclipse Che instances) for creating workspaces can also be configured. Configuring different Dev Spaces instances is done in the extension’s options page. The &lt;strong&gt;Dev Spaces&lt;/strong&gt; button provides a dropdown menu, allowing you to select which OpenShift Dev Spaces installation you want to create the workspace.&lt;/p&gt; &lt;p&gt;Figure 2 shows a quick demo of the extension in action. In the demo, we add a new Dev Spaces instance in the extension’s options, and start a new workspace on the newly added instance with the new &lt;strong&gt;Dev Spaces&lt;/strong&gt; button on GitHub.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/quick-demo.gif"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/quick-demo.gif" width="1600" height="1060" alt="A demo of how to use the Dev Spaces button, adding new Dev Spaces endpoint and creating a workspace." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2. A demo of how to use the Dev Spaces button. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;How does the Dev Spaces button work?&lt;/h2&gt; &lt;p&gt;If you have worked with OpenShift Dev Spaces (or the upstream project Eclipse Che®) before, you may already know that you can create workspaces by constructing and accessing a custom URL.&lt;/p&gt; &lt;p&gt;The custom URL consists of at least two main parts. There can be more parts if you want to customize the workspace further with &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_dev_spaces/3.4/html/user_guide/user-onboarding#optional-parameters-for-the-urls-for-starting-a-new-workspace"&gt;URL parameters&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Figure 3 displays a simple example of creating a new workspace with the &lt;code&gt;https://github.com/&lt;user&gt;/&lt;repo&gt;&lt;/code&gt; repository on the imaginary &lt;code&gt;https://devspaces.example.com&lt;/code&gt; Dev Spaces instance.&lt;/p&gt; &lt;p&gt;For a concrete example, try accessing &lt;code&gt;https://workspaces.openshift.com/#https://github.com/che-incubator/quarkus-api-example&lt;/code&gt; to create a new workspace on the Developer Sandbox for Red Hat OpenShift using the &lt;code&gt;https://github.com/che-incubator/quarkus-api-example&lt;/code&gt; GitHub project.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/URL.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/URL.png?itok=fTXrCTAc" width="600" height="138" alt="Example of a URL to create a new Dev Spaces workspace." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3. The URL used to create a new workspace in OpenShift Dev Spaces.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Clicking the &lt;strong&gt;Dev Spaces&lt;/strong&gt; button is essentially just accessing a custom-made URL. As the customization options for the URL grows, creating the custom URL by hand can be more time-consuming. The button is there for convenience, constructing URLs so you don’t have to.&lt;/p&gt; &lt;h2&gt;Installing the web extension on an air-gapped environment&lt;/h2&gt; &lt;p&gt;You can download the web extension’s source code from the &lt;a href="https://github.com/redhat-developer/try-in-dev-spaces-browser-extension"&gt;GitHub repository&lt;/a&gt;, build and sideload it into your browser.&lt;/p&gt; &lt;p&gt;To build the extension, run the following on a non-air-gapped machine:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ git clone https://github.com/redhat-developer/try-in-dev-spaces-browser-extension/tree/v1.0.0 $ cd try-in-dev-spaces-browser-extension/ $ yarn $ yarn build:prod # build the extension for Chromium based browsers $ yarn build:prod-sf # build the extension for Safari and Firefox&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can find the built extension for Chromium-based browsers in &lt;code&gt;dist/chromium&lt;/code&gt; and the extension built for Safari and Firefox in &lt;code&gt;dist/safari-firefox&lt;/code&gt;. Copy the built extension to the air-gapped machine and sideload the extension to the web browser by following the browser-specific steps from this &lt;a href="https://github.com/redhat-developer/try-in-dev-spaces-browser-extension/blob/main/CONTRIBUTING.md"&gt;document&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Upcoming plans for Try in Dev Spaces&lt;/h2&gt; &lt;p&gt;We plan to expand the extension's functionality by adding support for Azure DevOps Services, GitLab, and BitBucket in a future release. Additionally, we will make it easier to configure the created workspace using URL parameters (e.g., automatically setting up Git remotes when starting a workspace from a forked repository). If you have a question, please &lt;a href="https://github.com/redhat-developer/try-in-dev-spaces-browser-extension/issues/new"&gt;create an issue&lt;/a&gt; in the GitHub repository. We welcome your feedback.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/22/how-create-workspace-try-dev-spaces-extension" title="How to create a workspace via Try in Dev Spaces extension"&gt;How to create a workspace via Try in Dev Spaces extension&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>David Kwon</dc:creator><dc:date>2023-06-22T07:00:00Z</dc:date></entry><entry><title>New C++ features in GCC 13</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/21/new-c-features-gcc-13" /><author><name>Marek Polacek</name></author><id>0f8eb019-7e52-4ecf-9eac-a7e573abcde8</id><updated>2023-06-21T07:00:00Z</updated><published>2023-06-21T07:00:00Z</published><summary type="html">&lt;p&gt;The latest major version of the &lt;a href="https://gcc.gnu.org/"&gt;GNU Compiler Collection&lt;/a&gt; (GCC), 13.1, was released in April 2023. Like every major GCC release, this version brings many&lt;a href="https://gcc.gnu.org/gcc-13/changes.html"&gt; additions, improvements, bug fixes, and new features&lt;/a&gt;. GCC 13 is already the system compiler in&lt;a href="https://fedoraproject.org/wiki/Changes/GNUToolchainF38"&gt; Fedora 38&lt;/a&gt;. &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) users will get GCC 13 in the Red Hat GCC Toolset (RHEL 8 and RHEL 9). It's also possible to try GCC 13 on &lt;a href="https://godbolt.org/"&gt;godbolt.org&lt;/a&gt; and similar web pages.&lt;/p&gt; &lt;p&gt;Like the article I wrote about&lt;a href="https://developers.redhat.com/blog/2020/09/24/new-c-features-in-gcc-10"&gt; GCC 10&lt;/a&gt; and &lt;a href="https://developers.redhat.com/articles/2022/04/25/new-c-features-gcc-12"&gt;GCC 12&lt;/a&gt;, this article describes only new features implemented in the &lt;a href="https://developers.redhat.com/topics/c"&gt;C++&lt;/a&gt; front end; it does not discuss developments in the C++ language itself. Interesting changes in the standard C++ library that comes with GCC 13 are described in a separate blog post: &lt;a href="https://developers.redhat.com/articles/2023/04/19/new-c-features-gcc-13"&gt;New C features in GCC 13&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The default dialect in GCC 13 is &lt;code&gt;-std=gnu++17&lt;/code&gt;.  You can use the &lt;code&gt;-std=c++23&lt;/code&gt; or &lt;code&gt;-std=gnu++23&lt;/code&gt; command-line options to enable C++23 features, and similarly for C++20 and others. Note that C++20 and C++23 features are still experimental in GCC 13.&lt;/p&gt; &lt;h2&gt;C++23 features&lt;/h2&gt; &lt;p&gt;This section describes the following new C++23 features:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;static_assert (false)&lt;/code&gt; in templates&lt;/li&gt; &lt;li&gt;De-deprecating volatile compound operations&lt;/li&gt; &lt;li&gt;Relaxing &lt;code&gt;constexpr&lt;/code&gt; restrictions&lt;/li&gt; &lt;li&gt;Static operators&lt;/li&gt; &lt;li&gt;Extended floating-point types&lt;/li&gt; &lt;li&gt;Simpler implicit move&lt;/li&gt; &lt;li&gt;Equality operator fix&lt;/li&gt; &lt;li&gt;Portable assumptions&lt;/li&gt; &lt;li&gt;&lt;code&gt;char8_t &lt;/code&gt;compatibility fix&lt;/li&gt; &lt;li&gt;Labels at the end of compound statements&lt;/li&gt; &lt;li&gt;Traits to detect reference binding to temporary&lt;/li&gt; &lt;li&gt;C++ Contracts&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;static_assert (false) in templates&lt;/h3&gt; &lt;p&gt;GCC 13 resolves &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2593r0.html"&gt;P2593R0&lt;/a&gt; / &lt;a href="https://cplusplus.github.io/CWG/issues/2518.html"&gt;CWG 2518&lt;/a&gt;. The consequence is that a failing &lt;code&gt;static_assert&lt;/code&gt; is only ill-formed at instantiation time. In other words, this program compiles without errors in all C++ modes with GCC 13:&lt;/p&gt; &lt;pre&gt; template&lt;typename&gt; void f() { static_assert (false, ""); } &lt;/pre&gt; &lt;p&gt;because &lt;code&gt;static_assert (false)&lt;/code&gt; in uninstantiated templates is now accepted. (GCC 12 rejected the example above.)&lt;/p&gt; &lt;h3&gt;De-deprecating volatile compound operations&lt;/h3&gt; &lt;p&gt;&lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p2327r1.pdf"&gt;P2327R1&lt;/a&gt; partially reverts C++20 &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1152r4.html"&gt;P1152R4&lt;/a&gt;, which deprecated many uses of &lt;code&gt;volatile&lt;/code&gt;. As a consequence, bit-wise operations on volatile operands no longer warn:&lt;/p&gt; &lt;pre&gt; volatile int vi; int i; void g() { vi ^= i; // no -Wvolatile warning vi |= i; // no -Wvolatile warning vi &amp;= i; // no -Wvolatile warning }&lt;/pre&gt; &lt;p&gt;The change was backported to GCC 12 and 11 as well, so those versions also don’t warn for the test case above. A related defect report, &lt;a href="https://cplusplus.github.io/CWG/issues/2654.html"&gt;CWG 2654&lt;/a&gt;, was recently approved, meaning that the rest of the compound assignment operators were un-deprecated as well. GCC 13 already implements this defect report, so the warning doesn’t trigger for other compound operations such as &lt;code&gt;+=&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Relaxing constexpr restrictions&lt;/h3&gt; &lt;p&gt;It’s become customary to relax restrictions about the usage of the &lt;code&gt;constexpr&lt;/code&gt; keyword since its introduction in C++11. C++23 doesn’t break this habit. In C++23 (but not earlier modes), &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2647r1.html"&gt;P2647R1&lt;/a&gt; allows using &lt;code&gt;static constexpr&lt;/code&gt; variables in &lt;code&gt;constexpr&lt;/code&gt; functions:&lt;/p&gt; &lt;pre&gt; constexpr char test () { static constexpr char c[] = "Hello World"; // OK in C++23 return c[1]; } static_assert (test () == 'e'); &lt;/pre&gt; &lt;p&gt;In a similar vein, &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2448r2.html"&gt;P2448R2&lt;/a&gt; brings further &lt;code&gt;constexpr&lt;/code&gt; relaxation: in C++23, a &lt;code&gt;constexpr&lt;/code&gt; function’s return type or the type of its parameter does not have to be a literal type anymore, and, perhaps more importantly, a &lt;code&gt;constexpr&lt;/code&gt; function does not necessarily need to satisfy the requirement of a core constant expression (but actually calling such a function will result in a compile-time error). The intent is to allow functions to be marked &lt;code&gt;constexpr&lt;/code&gt; that will later become usable in a constant expression, once other functions that they call become &lt;code&gt;constexpr&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;GCC offers a new option, &lt;code&gt;-Winvalid-constexpr&lt;/code&gt;, to get a diagnostic when a function could not be invoked in a &lt;code&gt;constexpr&lt;/code&gt; context yet even in C++23 mode.&lt;/p&gt; &lt;pre&gt; void f (int&amp; i); constexpr void g (int&amp; i) { f(i); // warns by default in C++20, in C++23 only with -Winvalid-constexpr }&lt;/pre&gt; &lt;h3&gt;Static operators&lt;/h3&gt; &lt;p&gt;GCC 13 implements both &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p1169r4.html"&gt;P1169R4&lt;/a&gt; - &lt;code&gt;static operator()&lt;/code&gt; and &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2589r1.pdf"&gt;P2589R1&lt;/a&gt; - &lt;code&gt;static operator[]&lt;/code&gt;. As the names suggest, these proposals allow the programmer to create a static function call operator and a static subscript operator. Every non-static member function needs to pass the invisible &lt;code&gt;this&lt;/code&gt; pointer, which causes additional overhead when such a function is invoked. A static member function avoids the overhead because it doesn’t get the implicit object parameter.&lt;/p&gt; &lt;pre&gt; struct S { static constexpr bool operator() (int x, int y) { return x &lt; y; } }; constexpr S s; static_assert (s (1, 2)); void g() { S::operator()(1, 2); // OK in C++23 } &lt;/pre&gt; &lt;p&gt;Similarly, &lt;code&gt;operator[]&lt;/code&gt; can be marked &lt;code&gt;static&lt;/code&gt; as well:&lt;/p&gt; &lt;pre&gt; struct S { S() {} static int&amp; operator[]() { return mem[0]; } static int mem[64]; }; void g() { S s; s[]++; }&lt;/pre&gt; &lt;p&gt;Interested readers can read more about the motivation for this change &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p1169r4.html#motivation"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Extended floating-point types&lt;/h3&gt; &lt;p&gt;Since GCC 13 implements &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p1467r9.html"&gt;P1467R9&lt;/a&gt;, users can now use types such as &lt;code&gt;std::float16_t&lt;/code&gt; and similar:&lt;/p&gt; &lt;pre&gt; #include &lt;stdfloat&gt; int main () { std::float16_t f16 = 1.0f16; std::float32_t f32 = 2.0f32; std::float64_t f64 = 3.0f64; std::float128_t f128 = 4.0f128; }&lt;/pre&gt; &lt;p&gt;These types are becoming popular in fields like machine learning, computer graphics, weather modelers and similar, where it’s typically required to perform a huge amount of computations, but what precision is important depends on the particular use case. &lt;code&gt;std::float32_t&lt;/code&gt; and &lt;code&gt;std::float64_t&lt;/code&gt; are available on almost every architecture; &lt;code&gt;std::float16_t&lt;/code&gt; is currently available on x86_64, aarch64, and a few other architectures; and &lt;code&gt;std::float128_t&lt;/code&gt; is available on architectures that support the &lt;code&gt;__float128&lt;/code&gt;/&lt;code&gt;_Float128&lt;/code&gt; types.&lt;/p&gt; &lt;p&gt;On x86_64 and aarch64, &lt;code&gt;std::bfloat16&lt;/code&gt; is supported as well (the support comes with software emulation as well):&lt;/p&gt; &lt;pre&gt; std::bfloat16_t x = 1.0bf16;&lt;/pre&gt; &lt;h3&gt;Simpler implicit move&lt;/h3&gt; &lt;p&gt;The rules mandating implicit move unfortunately keep changing; over the years we have had at least &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0527r1.html"&gt;P0527R1&lt;/a&gt;, &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1155r3.html"&gt;P1155R3&lt;/a&gt;, and &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1825r0.html"&gt;P1825R0&lt;/a&gt;. C++23 brought &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2266r3.html"&gt;P2266R3&lt;/a&gt;, attempting to simplify the rules. For example, the cumbersome maybe-double overload resolution rule was removed. Additionally, P2266 enabled the implicit move even for functions that return references, e.g.:&lt;/p&gt; &lt;pre&gt; struct X { }; X&amp;&amp; foo (X&amp;&amp; x) { return x; } &lt;/pre&gt; &lt;p&gt;As a consequence, previously valid code may not compile anymore in C++23:&lt;/p&gt; &lt;pre&gt; int&amp; g(int&amp;&amp; x) { return x; } &lt;/pre&gt; &lt;p&gt;Because &lt;code&gt;x&lt;/code&gt; is treated as an rvalue in C++23, and it’s not allowed to bind a non-const lvalue reference to an rvalue. For more information, please see the &lt;a href="https://gcc.gnu.org/gcc-13/porting_to.html"&gt;Porting To&lt;/a&gt; documentation.&lt;/p&gt; &lt;h3&gt;Equality operator fix&lt;/h3&gt; &lt;p&gt;As a &lt;a href="https://developers.redhat.com/articles/2022/03/29/c-standardization-core-language-progress-2021#what_s_in_the_pipeline_for_c__23_"&gt;previous blog&lt;/a&gt; explained, the implicit reversing of &lt;code&gt;operator==&lt;/code&gt; made some valid C++17 code ill-formed in C++20, for instance when a class defines comparison operators that are accidentally asymmetric:&lt;/p&gt; &lt;pre&gt; struct S { bool operator==(const S&amp;) { return true; } // mistakenly non-const bool operator!=(const S&amp;) { return false; } // mistakenly non-const }; bool b = S{} != S{}; // well-formed in C++17, ambiguous in C++20 &lt;/pre&gt; &lt;p&gt;The problem was that the asymmetric &lt;code&gt;operator==&lt;/code&gt; was compared to itself in reverse. GCC implemented a tiebreaker to make the test case above work even in C++20, but the C++ committee resolved the issue in a different way: &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2468r2.html"&gt;P2468R2&lt;/a&gt; says that if there is an &lt;code&gt;operator!=&lt;/code&gt; with the same parameter types as the &lt;code&gt;operator==&lt;/code&gt;, the reversed form of the &lt;code&gt;operator==&lt;/code&gt; is ignored. GCC 13 implements the standardized approach.&lt;/p&gt; &lt;h3&gt;Portable assumptions&lt;/h3&gt; &lt;p&gt;GCC 13 gained support for &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p1774r8.pdf"&gt;P1774R8&lt;/a&gt;, a paper describing how a programmer can use the construct &lt;code&gt;[[assume(expr)]]&lt;/code&gt; to allow the compiler to assume that &lt;code&gt;expr&lt;/code&gt; is true and optimize the code accordingly. Most compilers already provide a non-standard way to achieve this. For example, GCC supports the &lt;code&gt;__builtin_unreachable&lt;/code&gt; built-in function. When used correctly, the resulting code may be both smaller and faster than a version without the &lt;code&gt;[[assume]]&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Consider the following (silly) function:&lt;/p&gt; &lt;pre&gt; int foo (int x, int y) { [[assume (x &gt;= y)]]; if (x == y) return 0; else if (x &gt; y) return 1; else return -1; } &lt;/pre&gt; &lt;p&gt;And the difference in the (x86) output assembly without/with the &lt;code&gt;assume&lt;/code&gt; attribute:&lt;/p&gt; &lt;pre&gt; @@ -8,11 +8,7 @@ _Z3fooii: .cfi_startproc xorl %eax, %eax cmpl %esi, %edi - je .L1 - setg %al - movzbl %al, %eax - leal -1(%rax,%rax), %eax -.L1: + setne %al ret .cfi_endproc .LFE0: &lt;/pre&gt; &lt;p&gt;With the attribute, in this case, all the compiler needs to do is to check if &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are equal, because it knows it can assume that &lt;code&gt;x&lt;/code&gt; cannot be less than &lt;code&gt;y&lt;/code&gt;; this results in better output code. Such an optimization is typically the result of the Value Range Propagation optimization taking place.&lt;/p&gt; &lt;p&gt;Note, however, that if the assumption is violated, the code triggers undefined behavior and the compiler is then free to do absolutely anything, so the attribute should be used sparingly and with great care. Also note that the compiler is free to ignore the attribute altogether.&lt;/p&gt; &lt;h3&gt;char8_t compatibility fix&lt;/h3&gt; &lt;p&gt;&lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0482r6.html"&gt;P0482R6&lt;/a&gt;, which added the &lt;code&gt;char8_t&lt;/code&gt; type, didn’t permit&lt;/p&gt; &lt;pre&gt; const char arr[] = u8"hi";&lt;/pre&gt; &lt;p&gt;But that caused problems in practice, so the example above is allowed under &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2513r4.html"&gt;P2513R4&lt;/a&gt;, which GCC 13 implements.&lt;/p&gt; &lt;h3&gt;Labels at the end of compound statements&lt;/h3&gt; &lt;p&gt;GCC 13 implements proposal &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2324r2.pdf"&gt;P2324R2&lt;/a&gt;. C2X (the next major C language standard revision) has started allowing labels at the end of a compound statement (which is, for example, before a function’s final &lt;code&gt;}&lt;/code&gt;) without a following &lt;code&gt;;&lt;/code&gt;. The C2X proposal was implemented in GCC 11. To minimize differences between C and C++ in this regard, C++ followed suit:&lt;/p&gt; &lt;pre&gt; void p2324 () { first: int x; second: x = 1; last: // no error in C++23 }&lt;/pre&gt; &lt;h3&gt;Traits to detect reference binding to temporary&lt;/h3&gt; &lt;p&gt;GCC 13 supports &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p2255r2.html"&gt;P2255R2&lt;/a&gt;, which adds two new type traits to detect reference binding to a temporary. They can be used to detect code like&lt;/p&gt; &lt;pre&gt; std::pair&lt;const std::string&amp;, int&gt; p("meow", 1);&lt;/pre&gt; &lt;p&gt;which is incorrect because it always creates a dangling reference, because the &lt;code&gt;std::string&lt;/code&gt; temporary is created inside the selected constructor of &lt;code&gt;std::pair&lt;/code&gt;, and not outside it. These traits are called &lt;code&gt;std::reference_constructs_from_temporary&lt;/code&gt; and &lt;code&gt;std::reference_converts_from_temporary&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;We have made use of these new traits in the standard C++ library to detect buggy code. For example, certain wrong uses of &lt;code&gt;std::function&lt;/code&gt;, &lt;code&gt;std::pair&lt;/code&gt;, and &lt;code&gt;std::make_from_tuple&lt;/code&gt; are now caught and an error is issued.&lt;/p&gt; &lt;h3&gt;Contracts&lt;/h3&gt; &lt;p&gt;Even though C++ Contracts are not in the C++ standard yet (although they briefly were in &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/n4820.pdf"&gt;N4820&lt;/a&gt;—see &lt;em&gt;Contract Attributes&lt;/em&gt;), GCC 13 implements a draft of C++ Contracts. This feature is highly experimental and has to be enabled by the &lt;code&gt;-fcontracts&lt;/code&gt; option. (It also requires that the program is linked with &lt;code&gt;-lstdc++exp&lt;/code&gt;.) Here’s an example of the &lt;code&gt;pre&lt;/code&gt; feature:&lt;/p&gt; &lt;pre&gt; void f (int x) [[ pre: x &gt;= 0 ]] // line 3 { } int main () { f (1); // OK f (0); // OK f (-1); // oops } &lt;/pre&gt; &lt;p&gt;This program, when compiled with &lt;code&gt;-fcontracts -std=c++20&lt;/code&gt; and run, will output the following:&lt;/p&gt; &lt;pre&gt; $ ./contracts_demo contract violation in function f at g.C:3: x &gt;= 0 terminate called without an active exception Aborted (core dumped)&lt;/pre&gt; &lt;h2&gt;Defect report resolutions&lt;/h2&gt; &lt;p&gt;A number of defect reports were resolved in GCC 13. A few examples follow.&lt;/p&gt; &lt;h3&gt;operator[] and default arguments&lt;/h3&gt; &lt;p&gt;&lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p2128r6.pdf"&gt;P2128R6&lt;/a&gt;, which added support for the multidimensional subscript operator, meant to allow default arguments, but accidentally did not. This was fixed in &lt;a href="https://cplusplus.github.io/CWG/issues/2507.html"&gt;CWG 2507&lt;/a&gt;, and the following example compiles in C++23 mode:&lt;/p&gt; &lt;pre&gt; struct A { void operator[](int, int = 42); };&lt;/pre&gt; &lt;h3&gt;attributes on concepts&lt;/h3&gt; &lt;p&gt;Since &lt;a href="https://cplusplus.github.io/CWG/issues/2428.html"&gt;CWG 2428&lt;/a&gt;, it’s permitted to have attributes on concepts:&lt;/p&gt; &lt;pre&gt; template&lt;typename T&gt; concept C [[deprecated]] = true;&lt;/pre&gt; &lt;h3&gt;consteval in default arguments&lt;/h3&gt; &lt;p&gt;Spurred by problems revolving around the usage of &lt;code&gt;source_location::current&lt;/code&gt;, &lt;a href="https://cplusplus.github.io/CWG/issues/2631.html"&gt;CWG 2631&lt;/a&gt; clarifies that immediate function calls in default arguments are not evaluated until the default argument is used (rather than being evaluated where they are defined, as part of the semantic constraints checking).&lt;/p&gt; &lt;h2&gt;Additional updates&lt;/h2&gt; &lt;p&gt;This section describes other enhancements in GCC 13&lt;/p&gt; &lt;h3&gt;Concepts fixes&lt;/h3&gt; &lt;p&gt;The C++ Concepts code has gotten a lot of bug fixes and a number of loose ends were tied up.&lt;/p&gt; &lt;p&gt;If you had issues with GCC 12 on concepts-heavy code, chances are GCC 13 will do a much better job.&lt;/p&gt; &lt;h3&gt;Mixing of GNU and standard attributes&lt;/h3&gt; &lt;p&gt;GCC 13 allows mixing GNU and standard (of the &lt;code&gt;[[ ]]&lt;/code&gt; form) attributes. Not allowing it caused problems with code, like:&lt;/p&gt; &lt;pre&gt; struct __attribute__ ((may_alias)) alignas (2) struct S { };&lt;/pre&gt; &lt;p&gt;or:&lt;/p&gt; &lt;pre&gt; #define EXPORT __attribute__((visibility("default"))) struct [[nodiscard]] EXPORT F { };&lt;/pre&gt; &lt;h3&gt;Reduced memory usage and compile time&lt;/h3&gt; &lt;p&gt;In GCC 13, we implemented various optimizations that reduce memory usage of the compiler. For example, specialization of nested templated classes has been optimized by reducing the number of unnecessary substitutions. Details can be found &lt;a href="https://gcc.gnu.org/git/?p=gcc.git;a=commitdiff;h=cb7fd1ea85feea7ef65328330fc2577a95e99400"&gt;here&lt;/a&gt;.  Another optimization was to reduce compile time by improving hashing of typenames.&lt;/p&gt; &lt;p&gt;To improve compile times, the compiler in GCC 13 provides new built-ins which the standard C++ library can use. It is generally faster to use a compiler built-in rather than instantiating a (potentially large) number of class templates and similar. For instance, GCC 13 added &lt;code&gt;__is_convertible&lt;/code&gt; and &lt;code&gt;__is_nothrow_convertible&lt;/code&gt;, as well as &lt;code&gt;__remove_cv&lt;/code&gt;, &lt;code&gt;__remove_reference&lt;/code&gt; and &lt;code&gt;__remove_cvref&lt;/code&gt; built-ins.&lt;/p&gt; &lt;p&gt;Another optimization was to reduce the number of temporaries when initializing an array of &lt;code&gt;std::string&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;-nostdlib++&lt;/h3&gt; &lt;p&gt;The C++ front end now understands the new option &lt;code&gt;-nostdlib++&lt;/code&gt;, which enables linking without implicitly linking in the C++ standard library.&lt;/p&gt; &lt;h3&gt;-fconcepts option cleaned up&lt;/h3&gt; &lt;p&gt;Previously, &lt;code&gt;-fconcepts&lt;/code&gt; in C++17 meant the same thing as &lt;code&gt;-fconcepts-ts&lt;/code&gt; (enabling Concepts Technical Specification which allows constructs not allowed by the standard) in C++20. This oddity was cleaned up and now &lt;code&gt;-fconcepts&lt;/code&gt; no longer implies &lt;code&gt;-fconcepts-ts&lt;/code&gt; prior to C++20. (We recommend using &lt;code&gt;-std=c++20&lt;/code&gt; if your code uses C++ Concepts.)&lt;/p&gt; &lt;h2&gt;New and improved warnings&lt;/h2&gt; &lt;p&gt;GCC's set of warning options have been enhanced in GCC 13.&lt;/p&gt; &lt;h3&gt;-Wparentheses and operator=&lt;/h3&gt; &lt;p&gt;&lt;code&gt;-Wparentheses&lt;/code&gt; in GCC 13 warns when an &lt;code&gt;operator=&lt;/code&gt; is used as a truth condition:&lt;/p&gt; &lt;pre&gt; struct A { A&amp; operator=(int); operator bool(); }; void f (A a) { if (a = 0); // warn }&lt;/pre&gt; &lt;h3&gt;Various std::move warnings improved&lt;/h3&gt; &lt;p&gt;GCC 12 already had a warning which warns about pessimizing uses of &lt;code&gt;std::move&lt;/code&gt; in a return statement. (See a related &lt;a href="https://developers.redhat.com/blog/2019/04/12/understanding-when-not-to-stdmove-in-c"&gt;blog post&lt;/a&gt; for more on this.) However, the warning didn’t warn about returning a class &lt;em&gt;prvalues&lt;/em&gt;, where a &lt;code&gt;std::move&lt;/code&gt; also prevents the Return Value Optimization. This has been fixed, and the warning now warns about the &lt;code&gt;std::move&lt;/code&gt; in:&lt;/p&gt; &lt;pre&gt; T fn() { T t; return std::move (T{}); } &lt;/pre&gt; &lt;p&gt;as well. Moreover, &lt;code&gt;-Wpessimizing-move&lt;/code&gt; warns in more contexts. For example:&lt;/p&gt; &lt;pre&gt; T t = std::move(T()); T t(std::move(T())); T t{std::move(T())}; T t = {std::move(T())}; void foo (T); foo (std::move(T()));&lt;/pre&gt; &lt;p&gt;A related warning, &lt;code&gt;-Wredundant-move&lt;/code&gt;, was extended to warn when the user is moving a &lt;code&gt;const&lt;/code&gt; object as in:&lt;/p&gt; &lt;pre&gt; struct T { }; T f(const T&amp; t) { return std::move(t); } &lt;/pre&gt; &lt;p&gt;where the &lt;code&gt;std::move&lt;/code&gt; is redundant, because &lt;code&gt;T&lt;/code&gt; does not have a &lt;code&gt;T(const T&amp;&amp;)&lt;/code&gt; constructor (which is very unlikely). Even with the &lt;code&gt;std::move&lt;/code&gt;, &lt;code&gt;T(T&amp;&amp;)&lt;/code&gt; would not be used because it would mean losing the &lt;code&gt;const&lt;/code&gt; qualifier. Instead, &lt;code&gt;T(const T&amp;)&lt;/code&gt; will be called.&lt;/p&gt; &lt;h3&gt;New warning: -Wself-move&lt;/h3&gt; &lt;p&gt;Relatedly to the previous paragraph, GCC 13 gained a new warning, which warns about useless “self” moves as in the example below.&lt;/p&gt; &lt;pre&gt; int x = 42; x = std::move (x);&lt;/pre&gt; &lt;h3&gt;New warning: -Wdangling-reference&lt;/h3&gt; &lt;p&gt;GCC 13 implements a fairly bold new warning to detect bugs in the source code when a reference is bound to a temporary whose lifetime has ended, which is undefined behavior. The canonical example is&lt;/p&gt; &lt;pre&gt; int n = 1; const int&amp; r = std::max(n-1, n+1); // r is dangling &lt;/pre&gt; &lt;p&gt;where both temporaries (that had been created for &lt;code&gt;n-1&lt;/code&gt; and &lt;code&gt;n+1&lt;/code&gt;) were destroyed at the end of the full expression. This warning (enabled by &lt;code&gt;-Wall&lt;/code&gt;) detects this problem. It works by employing a heuristic which checks if a reference is initialized by a function call that returns a reference and at least one parameter of the called function is a reference that is bound to a temporary.&lt;/p&gt; &lt;p&gt;Because the compiler does not check the definition of the called function (and often the definition isn’t even visible), the warning can be fooled, although in practice it doesn’t happen very often. However, there are functions like &lt;code&gt;std::use_facet&lt;/code&gt; that take and return a reference but don’t return one of its arguments. In such cases, we suggest suppressing the warning by using a &lt;code&gt;#pragma&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; #pragma GCC diagnostic push #pragma GCC diagnostic ignored "-Wdangling-reference" const T&amp; foo (const T&amp;) { ... } #pragma GCC diagnostic pop&lt;/pre&gt; &lt;p&gt;Subsequently, the warning was extended to also warn about a common “footgun” concerning &lt;code&gt;std::minmax&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; auto v = std::minmax(1, 2);&lt;/pre&gt; &lt;p&gt;which, perhaps not obviously, also contains a dangling reference: the selected &lt;code&gt;std::minmax&lt;/code&gt; overload returns &lt;code&gt;std::pair&lt;const int&amp;, const int&amp;&gt;&lt;/code&gt; where the two &lt;code&gt;const int&lt;/code&gt; references are bound to temporaries. Since its inception, the warning has been tweaked a number of times. For instance, we adjusted it to ignore reference-like classes, because those tended to provoke false positives.&lt;/p&gt; &lt;h3&gt;New warning: -Wxor-used-as-pow&lt;/h3&gt; &lt;p&gt;This warning warns about suspicious uses of the exclusive OR operator &lt;code&gt;^&lt;/code&gt;. For instance, when the user writes &lt;code&gt;2^8&lt;/code&gt;, it’s likely that they actually meant &lt;code&gt;1 &lt;&lt; 8&lt;/code&gt;. To reduce the number of false positives and make the warning useful in practice, it only warns when the first operand is the decimal constant 2 or 10.&lt;/p&gt; &lt;h3&gt;New option: -Wchanges-meaning&lt;/h3&gt; &lt;p&gt;In C++, a name in a class must have the same meaning in the complete scope of the class.  To that effect, GCC 12 emits an &lt;code&gt;-fpermissive&lt;/code&gt; error for&lt;/p&gt; &lt;pre&gt; struct A {}; struct B { A a; struct A { }; }; // error, A changes meaning &lt;/pre&gt; &lt;p&gt;In GCC 13, it is possible to disable this particular diagnostic by using the new command-line option &lt;code&gt;-Wchanges-meaning&lt;/code&gt;. Having a dedicated option to control this diagnostic is useful because other compilers aren’t as consistent in detecting this invalid code.&lt;/p&gt; &lt;h3&gt;Color function names in diagnostic&lt;/h3&gt; &lt;p&gt;This change can be best demonstrated with a screenshot (Figure 1).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/c-plus-plus-color-function.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/c-plus-plus-color-function.png?itok=uUTLrP6r" width="600" height="380" alt="Function names appear in color in GCC 13." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: C function names formatted in color.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &lt;p&gt;As usual, I'd like to thank my coworkers at Red Hat who made the GNU C++ compiler so much better, notably Jason Merrill, Jakub Jelinek, Patrick Palka, and Jonathan Wakely.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/21/new-c-features-gcc-13" title="New C++ features in GCC 13"&gt;New C++ features in GCC 13&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Marek Polacek</dc:creator><dc:date>2023-06-21T07:00:00Z</dc:date></entry><entry><title type="html">Designing Quarkus Front-Ends with Vaadin made easy</title><link rel="alternate" href="https://www.mastertheboss.com/soa-cloud/quarkus/designing-quarkus-front-ends-with-vaadin-made-easy/" /><author><name>F.Marchioni</name></author><id>https://www.mastertheboss.com/soa-cloud/quarkus/designing-quarkus-front-ends-with-vaadin-made-easy/</id><updated>2023-06-20T08:26:55Z</updated><content type="html">Vaadin Flow provides a comprehensive set of UI components and tools for creating rich and interactive user interfaces, while Quarkus offers a lightweight and efficient Java framework for developing cloud-native applications. In this article, we will explore how to combine the strengths of Vaadin and Quarkus to build web applications with ease. What is Vaadin? ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Debugging in GDB: Create custom stack winders</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/19/debugging-gdb-create-custom-stack-winders" /><author><name>Andrew Burgess</name></author><id>1b158985-49f8-4ef2-8f7a-afa95cad693f</id><updated>2023-06-19T07:00:00Z</updated><published>2023-06-19T07:00:00Z</published><summary type="html">&lt;p&gt;In this article, we will walk through the process of creating a custom stack unwinder for the GNU Project Debugger (GDB) using GDB's &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; API. We'll first explore when writing such an unwinder might be necessary, then create a small example application that demonstrates a need for a custom unwinder before finally writing a custom unwinder for our application inside the debugger.&lt;/p&gt; &lt;p&gt;By the end of this tutorial, you'll be able to use our custom stack unwinder to allow GDB to create a full backtrace for our application.&lt;/p&gt; &lt;h2&gt;What is an unwinder?&lt;/h2&gt; &lt;p&gt;An unwinder is how GDB figures out the call stack of an inferior, for example, GDB's &lt;code&gt;backtrace&lt;/code&gt; command:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;Breakpoint 1, woof () at stack.c:4 4 return 0; (gdb) backtrace #0 woof () at stack.c:4 #1 0x000000000040111f in bar () at stack.c:10 #2 0x000000000040112f in foo () at stack.c:16 #3 0x000000000040113f in main () at stack.c:22 (gdb)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Figuring out frame #0 is easy; the current program counter (&lt;code&gt;$pc&lt;/code&gt;) value tells GDB which function the inferior is currently in. But to figure out the other frames, GDB needs to read information from the inferior's registers and memory. The unwinder is the component of GDB that performs this task.&lt;/p&gt; &lt;p&gt;Having an understanding of the inferior's frames isn't just used for displaying the backtrace, though; commands like &lt;code&gt;next&lt;/code&gt; and &lt;code&gt;finish&lt;/code&gt; also need an accurate understanding of the stack frames in order to function properly.&lt;/p&gt; &lt;p&gt;Any time GDB needs information about a frame beyond #0, an unwinder will have been used.&lt;/p&gt; &lt;h2&gt;What is a custom unwinder?&lt;/h2&gt; &lt;p&gt;GDB already has multiple built-in unwinders for all the major architectures GDB supports. By far, the most common unwinder will be the DWARF unwinder, which reads the DWARF debug information and uses it to unwind the stack for GDB.&lt;/p&gt; &lt;p&gt;But not all functions are compiled with debug information. When GDB finds a function without DWARF debug information, it falls back to a built-in prologue analysis unwinder.&lt;/p&gt; &lt;p&gt;The prologue analysis unwinder disassembles the instructions at the start of a function and uses this information, combined with an understanding of the architecture's ABI, to provide unwind information. For many functions, the prologue analysis unwinder will do a reasonable job. Still, there's a limit to how smart the prologue analysis unwinder can be, and GDB can never expect to handle every function this way.&lt;/p&gt; &lt;p&gt;And this is where the Python unwinder API comes in. Using this API, it is possible to write Python code that will be loaded into GDB. This code can then "claim" frames for which GDB is otherwise unable to unwind correctly, and the Python code can instead be used to provide the unwind information to GDB.&lt;/p&gt; &lt;h2&gt;Building an example use case&lt;/h2&gt; &lt;p&gt;In most well-written applications, very few functions will need the support of a custom unwinder. The sort of functions that GDB will struggle with are those that do unexpected things with the underlying machine state; for example, functions that manipulate the stack in unexpected ways are likely to confuse GDB.&lt;/p&gt; &lt;p&gt;The example application we're going to write does just that: it allocates a second stack and uses a small assembler function to switch to, and run a function on, the new stack.&lt;/p&gt; &lt;p&gt;GDB will have no problem unwinding the standard C frames, but the assembler function, which changes the stack, is going to confuse GDB, and initially, we will be unable to obtain a &lt;code&gt;backtrace&lt;/code&gt; through this function.&lt;/p&gt; &lt;p&gt;Of course, writing in assembly language means this application will only work for one architecture, in this case, x86-64, and the unwinder we eventually write will also be tied to this one architecture. This is perfectly normal; unwinders are dealing with machine registers, so it is expected that an unwinder will only apply to a single architecture.&lt;/p&gt; &lt;p&gt;The demonstration application is split into two files, first, we have &lt;code&gt;demo.c&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;#include &lt;stdio.h&gt; #include &lt;sys/mman.h&gt; #include &lt;unistd.h&gt; #include &lt;stdlib.h&gt; /* This function is in our assembly file. */ extern void run_on_new_stack (void *stack, void (*) (void)); /* Return pointer to the top of a new stack. */ static void * allocate_new_stack (void) { int pagesz = getpagesize (); void *ptr = mmap (NULL, pagesz, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE, -1, 0); if (ptr == MAP_FAILED) abort (); return ptr + pagesz; } /* A function to run on the alternative stack. */ static void func (void) { printf ("Hello world\n"); } /* Allocate a new stack. Run a function on the new stack. */ int main (void) { void *new_stack = allocate_new_stack (); run_on_new_stack (new_stack, func); return 0; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then we have &lt;code&gt;runon.S&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; .global run_on_new_stack run_on_new_stack: /* Incoming arguments: %rdi - top of new stack pointer, %rsi - function to call. Store previous %rbp and %rsp to the new stack. Set %rbp and $rsp to point to the new stack. Call the function in %rsi. */ mov %rbp, -8(%rdi) mov %rsp, -16(%rdi) add $-16, %rdi mov %rdi, %rbp mov %rdi, %rsp callq *%rsi movq 0(%rbp), %rsp movq 8(%rbp), %rbp ret .size run_on_new_stack, . - run_on_new_stack .type run_on_new_stack, @function &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Finally, compile the application like this:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;gcc -g3 -O0 -Wall -Werror -o demo demo.c runon.S&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now let's see how GDB handles stack unwinding without any additional support. For this, I'm using GDB 13.1:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ gdb -q demo Reading symbols from demo... (gdb) break func Breakpoint 1 at 0x4011b1: file demo.c, line 25. (gdb) run Starting program: /tmp/demo Breakpoint 1, func () at demo.c:25 25 printf ("Hello world\n"); (gdb) backtrace #0 func () at demo.c:25 #1 0x00000000004011fb in run_on_new_stack () at runon.S:19 #2 0x00007fffffffad68 in ?? () #3 0x00007fffffffad80 in ?? () #4 0x0000000000000000 in ?? () (gdb)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As you can see, GDB can unwind from &lt;code&gt;func&lt;/code&gt; just fine; after all, that is a "normal" function compiled with debug information. But GDB is unable to figure out how to unwind from &lt;code&gt;run_on_new_stack&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;What our application is actually doing&lt;/h3&gt; &lt;p&gt;Before we can write a custom unwinder in Python, we need to make sure we fully understand what the demonstration application is actually doing.&lt;/p&gt; &lt;p&gt;We have three frames: &lt;code&gt;main&lt;/code&gt;, &lt;code&gt;run_on_new_stack&lt;/code&gt;, and &lt;code&gt;func&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;In &lt;code&gt;main&lt;/code&gt;, just before we call &lt;code&gt;run_on_new_stack&lt;/code&gt;, the application’s stack looks like Figure 1.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack_01_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stack_01_0.png?itok=qh8NGQuG" width="532" height="397" alt="Stack in main, just before run_on_new_stack is called." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: Stack in main, just before run_on_new_stack is called.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;The register &lt;code&gt;%rbp&lt;/code&gt;, sometimes known as the frame pointer, points to the top of the frame for &lt;code&gt;main&lt;/code&gt;, while &lt;code&gt;%rsp&lt;/code&gt;, otherwise known as the stack pointer, points to the last valid address of the frame for &lt;code&gt;main&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;When we call from &lt;code&gt;main&lt;/code&gt; to &lt;code&gt;run_on_new_stack&lt;/code&gt;, the return address within &lt;code&gt;main&lt;/code&gt; is pushed onto the stack and &lt;code&gt;%rsp&lt;/code&gt; is updated. The stack now looks like Figure 2.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack_02_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stack_02_0.png?itok=VAH8dv9U" width="532" height="454" alt="State of the stack upon entry to run_on_new_stack." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: State of the stack upon entry to run_on_new_stack.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;In &lt;code&gt;main&lt;/code&gt;, we also allocated a new stack, and this was passed through as the first function argument to &lt;code&gt;run_on_new_stack&lt;/code&gt;. As such, register &lt;code&gt;%rdi&lt;/code&gt; points at an address just above the new stack, like this (Figure 3).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack_03_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stack_03_0.png?itok=MiI5PIb6" width="310" height="397" alt="Visualisation of the new, empty stack." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: Visualisation of the new, empty stack.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Within &lt;code&gt;run_on_new_stack&lt;/code&gt; we switch over to the new stack. The return address within &lt;code&gt;main&lt;/code&gt; is left on the original stack, and the pointers (&lt;code&gt;%rbp&lt;/code&gt; and &lt;code&gt;%rsp&lt;/code&gt;) to the original stack are backed up on the new stack, and then updated to point at the new stack. We then call &lt;code&gt;func&lt;/code&gt;, which will push the return address within &lt;code&gt;run_on_new_stack&lt;/code&gt; onto the new stack. Once we are in &lt;code&gt;func&lt;/code&gt;, the state of the two stacks is now as shown in Figures 4 and 5.&lt;/p&gt; &lt;table border="0" cellpadding="1" cellspacing="1"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack_04_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stack_04_0.png?itok=gstn156K" width="443" height="397" alt="Layout of the original stack once run_on_new_stack has switched to the new stack." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: Layout of the original stack once run_on_new_stack has switched to the new stack.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;/td&gt; &lt;td&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack_05_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stack_05_0.png?itok=lK6M13ca" width="532" height="454" alt="Layout of new stack." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: Layout of new stack.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;When unwinding, GDB doesn't understand how to use the information on the new stack to find the original stack, and so the &lt;code&gt;backtrace&lt;/code&gt; is incomplete. This is the problem that our custom unwinder will solve for us.&lt;/p&gt; &lt;h3&gt;Starting our custom unwinder&lt;/h3&gt; &lt;p&gt;The custom unwinder will be written as a Python script in the file &lt;code&gt;runon-unwind.py&lt;/code&gt;, which we can then source in GDB to provide the extra functionality.&lt;/p&gt; &lt;p&gt;In GDB's Python API, an unwinder is an object that implements the &lt;code&gt;__call__&lt;/code&gt; method. GDB will call each unwinder object for every frame; the unwinder should return &lt;code&gt;None&lt;/code&gt; if the unwinder doesn't handle the frame or return a &lt;code&gt;gdb.UnwindInfo&lt;/code&gt; object if the unwinder wishes to take responsibility for the frame.&lt;/p&gt; &lt;p&gt;Let's start by writing an empty unwinder that doesn't claim any frames:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;from gdb.unwinder import Unwinder class runto_unwinder(Unwinder): def __init__(self): super().__init__("runto_unwinder") def __call__(self, pending_frame): return None gdb.unwinder.register_unwinder(None, runto_unwinder(), replace=True)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The last line of this file is responsible for registering the new unwinder with GDB. The first argument &lt;code&gt;None&lt;/code&gt; tells GDB to register this unwinder in the global scope, but it is also possible to register an unwinder for a specific object file or a specific program space. We'll not cover these cases in this tutorial, but the &lt;a href="https://sourceware.org/gdb/current/onlinedocs/gdb.html/Unwinding-Frames-in-Python.html"&gt;GDB documentation&lt;/a&gt; has more details.&lt;/p&gt; &lt;p&gt;The second argument to &lt;code&gt;register_unwinder&lt;/code&gt; is our new unwinder object. We'll discuss this more below.&lt;/p&gt; &lt;p&gt;The final argument &lt;code&gt;replace=True&lt;/code&gt; indicates that this new unwinder should replace any existing unwinder with the same name. This is useful when developing the unwinder as we can adjust our script and re-source it from GDB; the updated unwinder will then replace the existing one.&lt;/p&gt; &lt;p&gt;In our unwinder object &lt;code&gt;runto_unwinder&lt;/code&gt;, the constructor just calls the parent constructor and passes in a name for our unwinder. The name can be used within GDB to disable and enable the unwinder using the &lt;code&gt;disable unwinder&lt;/code&gt; and &lt;code&gt;enable unwinder&lt;/code&gt; commands, respectively. There is also &lt;code&gt;info unwinder&lt;/code&gt; which lists all the registered Python unwinders.&lt;/p&gt; &lt;p&gt;Our unwinder object also implements the required &lt;code&gt;__call__&lt;/code&gt; method. This method is passed a &lt;code&gt;gdb.PendingFrame&lt;/code&gt; object in &lt;code&gt;pending_frame&lt;/code&gt;. This pending frame describes the frame that is searching for an unwinder. We must examine this object and decide whether this unwinder applies to this pending frame. By returning &lt;code&gt;None&lt;/code&gt;, our unwinder is currently telling GDB that we don't wish to claim &lt;code&gt;pending_frame&lt;/code&gt;, our unwinder as it currently stands will not claim any frames, but we can start to address that next.&lt;/p&gt; &lt;h3&gt;Identifying frames to claim&lt;/h3&gt; &lt;p&gt;The first task our new unwinder needs to do is to decide which frame, or frames, should be claimed and which should not be claimed. Any frames not claimed by our unwinder will be offered to any other registered unwinders and will then be offered to GDB's built-in unwinders.&lt;/p&gt; &lt;p&gt;The easiest way to decide if we should claim a frame or not is to compare the program-counter address within the frame to the address range of the function we're claiming for—in this case, &lt;code&gt;run_on_new_stack&lt;/code&gt;. We can easily find the program-counter address for the frame by reading the &lt;code&gt;$pc&lt;/code&gt; register. This is done using the &lt;code&gt;read_register&lt;/code&gt; method of the &lt;code&gt;gdb.PendingFrame&lt;/code&gt; class.&lt;/p&gt; &lt;p&gt;Having read &lt;code&gt;$pc&lt;/code&gt;, we need an address range to compare against. For that, we will make use of GDB's disassembler. We will disassemble &lt;code&gt;run_on_new_stack&lt;/code&gt; and extract the address of each instruction. We can then use the first and last addresses as the lower and upper bounds that our unwinder should claim.&lt;/p&gt; &lt;p&gt;Update &lt;code&gt;runon-unwinder.py&lt;/code&gt; like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;from gdb.unwinder import Unwinder _unwind_analysis = None def analyze(): global _unwind_analysis # Disassemble the run_on_new_stack function. disasm = gdb.execute("disassemble run_on_new_stack", False, True) # Discard the first and last lines, these don't contain # disassembled instructions, and are of no interest. disasm = disasm.splitlines()[1:-1] # Extract the address of each instruction, and store these # addresses into the global _unwind_analysis list. disasm = [int(l.lstrip().split()[0], 16) for l in disasm] _unwind_analysis = disasm class runto_unwinder(Unwinder): def __init__(self): super().__init__("runto_unwinder") def __call__(self, pending_frame): # Analyze the function we're going to unwind. global _unwind_analysis if _unwind_analysis is None: analyze() # If this is not a frame we handle then return None. pc = pending_frame.read_register("pc") if pc &lt; _unwind_analysis[0] or pc &gt; _unwind_analysis[-1]: return None print(f"Found a frame we can handle at: {pc}") return None gdb.unwinder.register_unwinder(None, runto_unwinder(), replace=True)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The new &lt;code&gt;analyze&lt;/code&gt; function disassembles &lt;code&gt;run_on_new_stack&lt;/code&gt; and stores the address of each instruction in the global &lt;code&gt;_unwind_analysis&lt;/code&gt; list.&lt;/p&gt; &lt;p&gt;In &lt;code&gt;runto_unwinder.__call__&lt;/code&gt; we initialize &lt;code&gt;_unwind_analysis&lt;/code&gt; by calling &lt;code&gt;analyze&lt;/code&gt; once. We read &lt;code&gt;$pc&lt;/code&gt; by calling &lt;code&gt;pending_frame.read_register&lt;/code&gt;, and then we compare &lt;code&gt;pc&lt;/code&gt; to the first and last addresses in &lt;code&gt;_unwind_analysis&lt;/code&gt;. If the frame's program-counter is outside of the accepted range, then we return &lt;code&gt;None&lt;/code&gt;; this indicates to GDB that we don't wish to claim this frame.&lt;/p&gt; &lt;p&gt;If the frame's program-counter is within the range of &lt;code&gt;run_on_new_stack&lt;/code&gt;, then we print a message, and, for now, also return &lt;code&gt;None&lt;/code&gt;—don't worry, though, we'll soon be doing more than returning &lt;code&gt;None&lt;/code&gt; here, but right now, let's test our code.&lt;/p&gt; &lt;p&gt;Using the same demonstration application as before, here's an example GDB session:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ gdb -q demo Reading symbols from demo... (gdb) break func Breakpoint 1 at 0x4011b1: file demo.c, line 25. (gdb) run Starting program: /tmp/demo Breakpoint 1, func () at demo.c:25 25 printf ("Hello world\n"); (gdb) source runto-unwind.py (gdb) backtrace Found a frame we can handle at: 0x4011fb &lt;run_on_new_stack+20&gt; #0 func () at demo.c:25 #1 0x00000000004011fb in run_on_new_stack () at runon.S:19 #2 0x00007fffffffad38 in ?? () #3 0x00007fffffffad50 in ?? () #4 0x0000000000000000 in ?? () (gdb)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Notice the line: &lt;code&gt;Found a frame we can handle at: 0x4011fb &lt;run_on_new_stack+20&gt;&lt;/code&gt;. Don't worry if the addresses you see are different; what's important is that the message is printed—and printed just once. This indicates that our unwinder has identified a single frame it wishes to claim. The address from that line, &lt;code&gt;0x4011fb&lt;/code&gt;, matches the address from frame #1, the &lt;code&gt;run_on_new_stack&lt;/code&gt; frame; this shows that the correct frame was claimed.&lt;/p&gt; &lt;h3&gt;A detour into frame-ids&lt;/h3&gt; &lt;p&gt;The next step is to update the &lt;code&gt;__call__&lt;/code&gt; method to return a value that indicates the frame has been claimed by this unwinder. However, in order to claim the frame, we must provide a frame-id for the frame.&lt;/p&gt; &lt;p&gt;A frame-id is a unique identifier generated by the unwinder that must be unique for each stack frame but the same for every address within a particular invocation of a function.&lt;/p&gt; &lt;p&gt;Imagine the case where GDB is stepping through a function. After each step, GDB needs to recognize if it is still in the same frame or not. After each step, the unwinder will be used to identify the frame and generate the frame-id again. So long as the generated frame-id is always the same, GDB will understand it is still in the same frame.&lt;/p&gt; &lt;p&gt;Within GDB, frame-ids are a tuple of stack-pointer and code-pointer addresses. Often unwinders use the stack address at entry to the function (typically called the frame base address), and the program address for the function's first instruction.&lt;/p&gt; &lt;p&gt;Within GDB's Python API, a frame-id is represented by any object that has the &lt;code&gt;sp&lt;/code&gt; and &lt;code&gt;pc&lt;/code&gt; attributes. These attributes should contain &lt;code&gt;gdb.Value&lt;/code&gt; objects representing their respective addresses.&lt;/p&gt; &lt;h3&gt;Creating a frame-ID and UnwindInfo object&lt;/h3&gt; &lt;p&gt;Now that we know about frame-ids, let's dive in and update our unwinder. We'll discuss these changes afterward. Update &lt;code&gt;runto-unwind.py&lt;/code&gt; as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;from gdb.unwinder import Unwinder _unwind_analysis = None def analyze(): global _unwind_analysis # Disassemble the run_on_new_stack function. disasm = gdb.execute("disassemble run_on_new_stack", False, True) # Discard the first and last lines, these don't contain # disassembled instructions, and are of no interest. disasm = disasm.splitlines()[1:-1] # Extract the address of each instruction, and store these # addresses into the global _unwind_analysis list. disasm = [int(l.lstrip().split()[0], 16) for l in disasm] _unwind_analysis = disasm class FrameID: def __init__(self, sp, pc): self.sp = sp self.pc = pc class runto_unwinder(Unwinder): def __init__(self): super().__init__("runto_unwinder") def __call__(self, pending_frame): # Analyze the function we're going to unwind. global _unwind_analysis if _unwind_analysis is None: analyze() # If this is not a frame we handle then return None. pc = pending_frame.read_register("pc") if pc &lt; _unwind_analysis[0] or pc &gt; _unwind_analysis[-1]: return None # Create a frame id that will remain consistent throughout # the frame, no matter what $pc we stop at. We use the $sp # value for the previous frame (this was our $sp on frame # entry), and we use the $pc for the start of the function. # # For the first four and last two instructions, the previous # $sp value can be found in the %rsp register. # # For the fifth and sixth instructions we need to fetch the # previous $sp value from the original stack. rsp = pending_frame.read_register("rsp") if pc &lt; _unwind_analysis[5] or pc &gt; _unwind_analysis[6]: frame_sp = rsp else: frame_sp = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % rsp) func_start = gdb.Value(_unwind_analysis[0]) frame_id = FrameID(frame_sp, func_start) # Create the unwind_info cache object which holds our unwound # registers. unwind_info = pending_frame.create_unwind_info(frame_id) print(f"Found a frame we can handle at: {pc}") return None gdb.unwinder.register_unwinder(None, runto_unwinder(), replace=True)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Currently, GDB doesn't include any helper classes that can be used to represent a frame-id, so we need to define our own – &lt;code&gt;FrameID&lt;/code&gt;. The only requirements are that this class has the &lt;code&gt;sp&lt;/code&gt; and &lt;code&gt;pc&lt;/code&gt; attributes.&lt;/p&gt; &lt;p&gt;Within the &lt;code&gt;__call__&lt;/code&gt; method we use the first address of &lt;code&gt;run_on_new_stack&lt;/code&gt; as the program-counter value for the frame-id. This is done with this line:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; func_start = gdb.Value(_unwind_analysis[0])&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For the stack-pointer address of the frame-id, we need to be smarter. When we first enter &lt;code&gt;run_on_new_stack&lt;/code&gt;, the previous stack-pointer value is still present in &lt;code&gt;%rsp&lt;/code&gt;, but within &lt;code&gt;run_on_new_stack&lt;/code&gt;, the &lt;code&gt;%rsp&lt;/code&gt; register is stored to the new stack and a new value loaded into &lt;code&gt;%rsp&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;To handle these two cases, we use the following block of code:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; if pc &lt; _unwind_analysis[5] or pc &gt; _unwind_analysis[6]: frame_sp = rsp else: frame_sp = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % rsp)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We choose between the two possible paths based on the current location within the function. The addresses &lt;code&gt;_unwind_analysis[5]&lt;/code&gt; and &lt;code&gt;_unwind_analysis[6]&lt;/code&gt; were chosen by reviewing the instruction disassembly for &lt;code&gt;run_on_new_stack&lt;/code&gt;. A good exercise would be to disassemble the function and convince yourself that the above choices are correct.&lt;/p&gt; &lt;p&gt;We can now create an instance of our &lt;code&gt;FrameID&lt;/code&gt; class and use this instance to create a &lt;code&gt;gdb.UnwindInfo&lt;/code&gt; object with these lines:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; frame_id = FrameID(frame_sp, func_start) # Create the unwind_info cache object which holds our unwound # registers. unwind_info = pending_frame.create_unwind_info(frame_id)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;gdb.UnwindInfo&lt;/code&gt; class is the last piece of the unwinder process. We will store unwound register values into our &lt;code&gt;unwind_info&lt;/code&gt; object and return this to GDB in order to claim this frame. However, we're not there just yet—for now, we're still printing a debug message and returning &lt;code&gt;None&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Adding unwound register values&lt;/h3&gt; &lt;p&gt;Having decided to claim this frame, and having created a &lt;code&gt;gdb.UnwindInfo&lt;/code&gt; object, we need to store some unwound register values in our new &lt;code&gt;unwind_info&lt;/code&gt; object.&lt;/p&gt; &lt;p&gt;The unwound value of a register is the value a register had in the previous frame.&lt;/p&gt; &lt;p&gt;Locating the previous register values will involve understanding the assembler code for the function being unwound. You don't need to provide previous values for every register; in some cases, the previous value of a register will not be available at all, in which case nothing can be done.&lt;/p&gt; &lt;p&gt;To keep the complexity of this example down, we are only going to provide previous values for 3 registers, the program counter, &lt;code&gt;%rsp&lt;/code&gt;, and &lt;code&gt;%rbp&lt;/code&gt;. These registers are enough to allow GDB to build a complete backtrace on x86-64. Once you've seen how these registers are supported, extending the example to support other registers as needed should be easy enough.&lt;/p&gt; &lt;p&gt;As before, let's just update &lt;code&gt;runon-unwind.py&lt;/code&gt;, and discuss the changes afterwards:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;from gdb.unwinder import Unwinder _unwind_analysis = None def analyze(): global _unwind_analysis # Disassemble the run_on_new_stack function. disasm = gdb.execute("disassemble run_on_new_stack", False, True) # Discard the first and last lines, these don't contain # disassembled instructions, and are of no interest. disasm = disasm.splitlines()[1:-1] # Extract the address of each instruction, and store these # addresses into the global _unwind_analysis list. disasm = [int(l.lstrip().split()[0], 16) for l in disasm] _unwind_analysis = disasm class FrameID: def __init__(self, sp, pc): self.sp = sp self.pc = pc class runto_unwinder(Unwinder): def __init__(self): super().__init__("runto_unwinder") def __call__(self, pending_frame): # Analyze the function we're going to unwind. global _unwind_analysis if _unwind_analysis is None: analyze() # If this is not a frame we handle then return None. pc = pending_frame.read_register("pc") if pc &lt; _unwind_analysis[0] or pc &gt; _unwind_analysis[-1]: return None # Create a frame id that will remain consistent throughout the # frame, no matter what $pc we stop at. We use the $sp value # for the previous frame (this was our $sp on frame entry), # and we use the $pc for the start of the function. # # For the first four and last two instructions, the previous # $sp value can be found in the %rsp register. # # For the fifth and sixth instructions we need to fetch the # previous $sp value from the original stack. rsp = pending_frame.read_register("rsp") if pc &lt; _unwind_analysis[5] or pc &gt; _unwind_analysis[6]: frame_sp = rsp else: frame_sp = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % rsp) func_start = gdb.Value(_unwind_analysis[0]) frame_id = FrameID(frame_sp, func_start) # Create the unwind_info cache object which holds our unwound # registers. unwind_info = pending_frame.create_unwind_info(frame_id) # Calculate the previous register values. Select the correct # previous value for $rbp based on where we are in the # function. if pc &lt; _unwind_analysis[4] or pc &gt; _unwind_analysis[7]: prev_rbp = pending_frame.read_register("rbp") else: prev_rbp = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % (rsp + 8)) # We use the previous $sp value in our frame-id, which is handy! prev_rsp = frame_sp # The previous $pc is always on the original (incoming) stack. prev_pc = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % (prev_rsp)) # And store the previous values into our cache. unwind_info.add_saved_register("rsp", prev_rsp) unwind_info.add_saved_register("rbp", prev_rbp) unwind_info.add_saved_register("pc", prev_pc) # Return the cache for GDB to use. return unwind_info gdb.unwinder.register_unwinder(None, runto_unwinder(), replace=True)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The most important part of this new version are the three calls to &lt;code&gt;unwind_info.add_saved_register&lt;/code&gt;; this is how we record the unwound register values. The first argument to these calls is the name of the register we are recording, and the second argument is the value that register had in the previous frame.&lt;/p&gt; &lt;p&gt;The three registers we record are &lt;code&gt;pc&lt;/code&gt;, &lt;code&gt;rsp&lt;/code&gt;, and &lt;code&gt;rbp&lt;/code&gt;. Figuring out the previous value for the first two registers is pretty easy. We already have the previous &lt;code&gt;rsp&lt;/code&gt; value, remember, this is what we used for our frame-id so that we can reuse that value here.&lt;/p&gt; &lt;p&gt;Recall from our earlier stack diagrams; the return address in &lt;code&gt;main&lt;/code&gt; was the last thing stored on the original stack, this is what the previous stack-pointer points at, so we can load the return address with this line:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; prev_pc = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % (prev_rsp))&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And this just leaves the previous &lt;code&gt;rbp&lt;/code&gt; value. Just like we found the previous &lt;code&gt;rsp&lt;/code&gt; value earlier, the current instruction within &lt;code&gt;run_on_new_stack&lt;/code&gt; will determine the location of the previous &lt;code&gt;rbp&lt;/code&gt; value. Initially the previous value is in the &lt;code&gt;rbp&lt;/code&gt; register, but we store this previous value to the new stack before calling &lt;code&gt;func&lt;/code&gt;. And so, to find the correct previous value, we need to switch based on the program-counter value, which we do with these lines:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; if pc &lt; _unwind_analysis[4] or pc &gt; _unwind_analysis[7]: prev_rbp = pending_frame.read_register("rbp") else: prev_rbp = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % (rsp + 8))&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The last update is to remove the debug message that we have been printing until now, and instead of returning &lt;code&gt;None&lt;/code&gt;, return our &lt;code&gt;gdb.UnwindInfo&lt;/code&gt; object &lt;code&gt;unwind_info&lt;/code&gt;. This tells GDB that our unwinder has claimed this frame. GDB will use the previous register values stored within &lt;code&gt;unwind_info&lt;/code&gt; when it needs to unwind through this frame.&lt;/p&gt; &lt;p&gt;So, for the last time, let's try our unwinder in GDB:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ gdb -q demo Reading symbols from demo... (gdb) break func Breakpoint 1 at 0x4011b1: file demo.c, line 25. (gdb) run Starting program: /tmp/demo Breakpoint 1, func () at demo.c:25 25 printf ("Hello world\n"); (gdb) source runon-unwind.py (gdb) backtrace #0 func () at demo.c:25 #1 0x00000000004011fb in run_on_new_stack () at runon.S:19 #2 0x00000000004011e0 in main () at demo.c:33 (gdb)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And success! We can now unwind through &lt;code&gt;run_on_new_stack&lt;/code&gt; back to &lt;code&gt;main&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Summary and conclusions&lt;/h3&gt; &lt;p&gt;Writing custom stack unwinders is not trivial; it requires a good understanding of the function being unwound and the architecture the unwinder is being written for. There is more to GDB's unwinder API than has been discussed in this brief introduction. The full details can all be found in the &lt;a href="https://sourceware.org/gdb/current/onlinedocs/gdb.html/Unwinding-Frames-in-Python.html"&gt;documentation&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/19/debugging-gdb-create-custom-stack-winders" title="Debugging in GDB: Create custom stack winders"&gt;Debugging in GDB: Create custom stack winders&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Andrew Burgess</dc:creator><dc:date>2023-06-19T07:00:00Z</dc:date></entry><entry><title type="html">Life in First Principles</title><link rel="alternate" href="http://www.ofbizian.com/2023/06/life-in-first-principles.html" /><author><name>Unknown</name></author><id>http://www.ofbizian.com/2023/06/life-in-first-principles.html</id><updated>2023-06-16T07:27:00Z</updated><content type="html">Let's express life through its finite ingredients. There are three resources in life that everything else depends on. Every time you waste any of them, they're gone forever. These are time, energy, and focus. TIME Time is the one variable that nobody has any control over. There are 24 hours in a day, 365 days in a year. Time offers the same equal consistency to everybody, but at different lengths. We are born, we live, and we die. All you can do is maximise the other variables in the time given to you, in a way meaningful to you. ENERGY Being alive is a prerequisite, but not sufficient to reach happiness. Given a lifetime, to maximise your purpose and happiness, depends on your energy levels. Energy is the ability to do things, physically or mentally. Having a body sufficiently healthy that will enable you to pursue your purpose. For some, this can be a physically strong body, having a good sleep, healthy diet, and regular exercise. For others, it can be sufficient to be able to get up from the bed and hold a pen. And for some even the ability to express your thoughts through a computer device (such as Stephen Hawking). Energy levels vary from person to person, but so are the energy needs. Energy is not a "have or have not" constant like life is, it is rather a variable that tends that changes every moment, and tends to go down with age. Energy is the multiplier that lets you get the best out of the time given to you. FOCUS Being lucky to be alive, and having sufficient energy, gives the optionality to spend your attention in many ways. Focus is about how we use our time and energy in a directed way. It is the ability to concentrate our attention in a direction that makes us happy, or spread and waste in the universe in a way benefiting others or nobody. Focus is the variable that we have most control over, and the variable that has the biggest power to change our life. Used in a purposeful way, even in short lifespan and limited energy levels, it has led to personal fulfilments, or human achievements that are remembered throughout millennials. Used purposelessly, can lead to wasted long life full of energy, and many regrets in a death bed. THE HAPPINESS FORMULA If time is a yes/no constant, and the energy level is a multiplier for every moment, then focus is the exponent of all. Every moment, we are alive, we have a certain energy level that we can use for something purposeful or waste for nothing. Then we have recharge again. Every moment we have the ability to focus our energy to things that matter to us, or waste it aimlessly. Life happiness is the sum of all moments we had, with sufficient energy to help us focus on things that makes us happy. Happiness is the sum of all finite moments where we focus our energy towards our purpose Every time we waste these finite resources, they're gone forever. Make sure you are alive first, healthy and energised second, and also focused on what makes you happy. These variables build on top of each other and require a delicate balance. Focus too much on one thing, and you may lose your life in an instant. Ignore your health, and your energy levels will suffer hindering the ability to focus. Do everything right, and still a meteor can hit you and end it all. There is no guarantee, or fairness in any of these, only the awareness of its working. This formula is re presentation of how these finite resources can be transformed into happiness in the equation called life.</content><dc:creator>Unknown</dc:creator></entry><entry><title>Quarkus 3.1.2.Final released - Maintenance release</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-3-1-2-final-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-3-1-2-final-released/</id><updated>2023-06-16T00:00:00Z</updated><published>2023-06-16T00:00:00Z</published><summary type="html">We released Quarkus 3.1.2.Final, the second maintenance release of our 3.1 release train. As usual, it contains bugfixes and documentation improvements. It should be a safe upgrade for anyone already using 3.1. If you are not already using 3.1, please refer to the Quarkus 3.1 migration guide. And if you...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2023-06-16T00:00:00Z</dc:date></entry></feed>
